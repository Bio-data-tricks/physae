#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os, json, argparse, math, random, sys
from dataclasses import dataclass
from typing import List, Optional, Dict, Any, Tuple
import optuna 
from optuna.samplers import TPESampler
import numpy as np
import torch
torch.set_float32_matmul_precision("high")   
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
torch.backends.cudnn.benchmark = True

import torch.nn as nn
import torch.nn.functional as F
import pytorch_lightning as pl
from torch.utils.data import DataLoader, Dataset
import matplotlib as mpl
mpl.use("Agg")  # backend non interactif pour cluster/headless
mpl.rcParams['font.family'] = ['DejaVu Sans', 'Segoe UI Emoji', 'Segoe UI Symbol']
mpl.rcParams['axes.unicode_minus'] = False
import matplotlib.pyplot as plt
import torch
import argparse, os, csv, math, json, random, numpy as np, torch, pytorch_lightning as pl
import optuna
from optuna.storages.journal import JournalFileBackend
from optuna.storages import JournalStorage
# ===========================================================
# 1) Configs globaux & normalisation (section "core")
# ============================================================
PARAMS = ['sig0', 'dsig', 'mf_CH4', 'baseline0', 'baseline1', 'baseline2', 'P', 'T']
PARAM_TO_IDX = {n:i for i,n in enumerate(PARAMS)}
LOG_SCALE_PARAMS = {'mf_CH4'}
LOG_FLOOR = 1e-7
NORM_PARAMS: Dict[str, tuple] = {}  # rempli par le builder

def norm_param_value(name: str, val: float):
     vmin, vmax = NORM_PARAMS[name]
     if name in LOG_SCALE_PARAMS:
         vmin = max(vmin, LOG_FLOOR); vmax = max(vmax, vmin*(1+1e-12)); val = max(val, LOG_FLOOR)
         lv, lmin, lmax = math.log10(val), math.log10(vmin), math.log10(vmax)
         return (lv - lmin) / (lmax - lmin)
     else:
        # Sécurité: éviter division par zéro si vmax == vmin
        # Utilise la plus petite valeur positive représentable en float64 (~2e-308) comme plancher.
        denom = max(vmax - vmin, sys.float_info.epsilon)
        return (val - vmin) / denom

def norm_param_torch(name: str, val_t: torch.Tensor) -> torch.Tensor:
     vmin, vmax = NORM_PARAMS[name]
     vmin_t = torch.as_tensor(vmin, dtype=val_t.dtype, device=val_t.device)
     vmax_t = torch.as_tensor(vmax, dtype=val_t.dtype, device=val_t.device)
     if name in LOG_SCALE_PARAMS:
         vmin_t = torch.clamp(vmin_t, min=LOG_FLOOR)
         vmax_t = torch.maximum(vmax_t, vmin_t*(1+torch.finfo(val_t.dtype).eps))
         val_t  = torch.clamp(val_t,  min=LOG_FLOOR)
         lval   = torch.log10(val_t); lmin = torch.log10(vmin_t); lmax = torch.log10(vmax_t)
         return (lval - lmin) / (lmax - lmin)
     else:
        # Sécurité: clamp du dénominateur (respecte le dtype: float32 ou float64)
        denom = (vmax_t - vmin_t).clamp_min(torch.finfo(val_t.dtype).eps)
        return (val_t - vmin_t) / denom

def unnorm_param_torch(name: str, val_norm_t: torch.Tensor) -> torch.Tensor:
    vmin, vmax = NORM_PARAMS[name]
    vmin_t = torch.as_tensor(vmin, dtype=val_norm_t.dtype, device=val_norm_t.device)
    vmax_t = torch.as_tensor(vmax, dtype=val_norm_t.dtype, device=val_norm_t.device)
    if name in LOG_SCALE_PARAMS:
        vmin_t = torch.clamp(vmin_t, min=LOG_FLOOR)
        vmax_t = torch.maximum(vmax_t, vmin_t*(1+torch.finfo(val_norm_t.dtype).eps))
        lmin   = torch.log10(vmin_t); lmax = torch.log10(vmax_t)
        lval   = val_norm_t*(lmax-lmin)+lmin
        return torch.pow(10.0, lval)
    else:
        return val_norm_t*(vmax_t-vmin_t)+vmin_t

# === NEW ===
from functools import lru_cache


@dataclass(frozen=True)
class TrainerDeviceConfig:
    """Configuration compacte pour instancier un ``pl.Trainer`` multi-device."""

    accelerator: str
    devices: int
    precision: str
    num_nodes: int = 1
    strategy: Optional[str] = None

    @property
    def world_size(self) -> int:
        return max(1, int(self.devices) * max(1, int(self.num_nodes)))

    @property
    def distributed(self) -> bool:
        return self.world_size > 1

    def to_trainer_kwargs(self) -> Dict[str, Any]:
        kwargs: Dict[str, Any] = {
            "accelerator": self.accelerator,
            "devices": self.devices,
            "num_nodes": self.num_nodes,
            "precision": self.precision,
        }
        if self.strategy:
            kwargs["strategy"] = self.strategy
        if self.accelerator == "gpu" and self.distributed:
            # SyncBatchNorm est essentiel pour la convergence multi-GPU
            kwargs.setdefault("sync_batchnorm", True)
        return kwargs

def preprocess_transitions(transitions_dict: Dict[str, list],
                           device: torch.device | str = "cpu",
                           dtype: torch.dtype = torch.float64) -> Dict[str, Dict[str, torch.Tensor]]:
    """
    Convertit une fois pour toutes les transitions par molécule en tenseurs.
    Retourne, pour chaque molécule, un dict {field: tensor [L]}.
    """
    KEYS = ['amplitude', 'center', 'gamma_air', 'gamma_self', 'n_air',
            'shift_air', 'gDicke', 'nDicke', 'lmf', 'nlmf']
    out: Dict[str, Dict[str, torch.Tensor]] = {}
    for mol, trans in transitions_dict.items():
        # trans est une liste de dicts (comme retourné par parse_csv_transitions)
        arr = {k: torch.tensor([t[k] for t in trans], device=device, dtype=dtype) for k in KEYS}
        out[mol] = arr
    return out

@lru_cache(maxsize=None)
def _physics_constants(device: str, dtype_name: str):
    """
    Mise en cache des constantes physiques par (device, dtype).
    """
    d = getattr(torch, dtype_name)
    dev = torch.device(device)
    C  = torch.tensor(2.99792458e10, dtype=d, device=dev)
    NA = torch.tensor(6.02214129e23, dtype=d, device=dev)
    KB = torch.tensor(1.380649e-16, dtype=d, device=dev)
    P0 = torch.tensor(1013.25, dtype=d, device=dev)
    T0 = torch.tensor(273.15, dtype=d, device=dev)
    L0 = torch.tensor(2.6867773e19, dtype=d, device=dev)
    TREF = torch.tensor(296.0, dtype=d, device=dev)
    tiny = torch.finfo(d).tiny
    return C, NA, KB, P0, T0, L0, TREF, tiny

# petites constantes numériques en module-level (pas critique, mais ça évite de les recalc)
ROOT_PI = math.sqrt(math.pi)
RT2LN2 = math.sqrt(math.log(2.0))


# ============================================================
# 1.b) Lissage et échelles d’entrée
# ============================================================
@torch.no_grad()
def lowess_firstN_start_value(y: torch.Tensor, Nwin: int = 20, iters: int = 2) -> torch.Tensor:
    """
    Lisse par LOWESS sur les Nwin premiers points et renvoie la valeur lissée au tout début (x=0).
    y : [N] ou [B,N] -> scalaire (ou [B])
    """
    def _one(y1d: torch.Tensor) -> torch.Tensor:
        assert y1d.ndim == 1
        N = y1d.numel()
        k = max(5, min(int(Nwin), N))  # borne
        if k <= 2:
            return y1d[0].to(torch.float64)

        dev = y1d.device
        y = y1d[:k].to(torch.float64)
        x = torch.arange(k, device=dev, dtype=torch.float64)
        x = x / max(1.0, float(k-1))  # [0..1]

        # poids tri-cube vs distance à 0
        d = x
        w = (1 - d.pow(3)).clamp(min=0).pow(3) + 1e-12

        # régression linéaire locale y ~ a + b*x
        X = torch.stack([torch.ones_like(x), x], dim=1)

        def _solve_wls(X, y, w):
            WX = X * w.unsqueeze(1)
            XtWX = X.T @ WX + 1e-12 * torch.eye(2, dtype=torch.float64, device=dev)
            XtWy = WX.T @ y
            return torch.linalg.solve(XtWX, XtWy)

        beta = _solve_wls(X, y, w)
        for _ in range(max(0, iters - 1)):
            r = y - (X @ beta)
            s = torch.median(torch.abs(r)) + 1e-12
            u = (r / (6*s)).clamp(min=-1, max=1)
            w_rob = (1 - u.pow(2)).clamp(min=0).pow(2)
            beta = _solve_wls(X, y, w * w_rob + 1e-12)

        return beta[0]  # intercept = valeur en x=0

    if y.ndim == 1:
        return _one(y).to(y.dtype)
    elif y.ndim == 2:
        vals = [ _one(y[i]) for i in range(y.shape[0]) ]
        return torch.stack(vals).to(y.dtype)
    else:
        raise ValueError("lowess_firstN_start_value attend un tensor 1D ou 2D.")

# ============================================================
# 2) Physique : parsing + forward multi-molécules
# ============================================================
def parse_csv_transitions(csv_str):
    transitions = []
    for line in csv_str.strip().splitlines():
        if not line.strip() or line.strip().startswith("#"): continue
        toks = [t.strip() for t in line.split(";")]
        while len(toks) < 14: toks.append('0')
        transitions.append({
            'mid': int(toks[0]), 'lid': int(float(toks[1])), 'center': float(toks[2]),
            'amplitude': float(toks[3]), 'gamma_air': float(toks[4]), 'gamma_self': float(toks[5]),
            'e0': float(toks[6]), 'n_air': float(toks[7]), 'shift_air': float(toks[8]),
            'abundance': float(toks[9]), 'gDicke': float(toks[10]), 'nDicke': float(toks[11]),
            'lmf': float(toks[12]), 'nlmf': float(toks[13]),
        })
    return transitions

def transitions_to_tensors(transitions, device):
    keys = ['amplitude', 'center', 'gamma_air', 'gamma_self', 'n_air',
            'shift_air', 'gDicke', 'nDicke', 'lmf', 'nlmf']
    return [torch.tensor([t[k] for t in transitions], dtype=torch.float32, device=device) for k in keys]

MOLECULE_PARAMS = {'CH4': {'M': 16.04, 'PL': 15.12}, 'H2O': {'M': 18.02, 'PL': 15.12}}

# — Faddeeva (W(z)) approx —
_b = torch.tensor([-0.0173-0.0463j, -0.7399+0.8395j, 5.8406+0.9536j, -5.5834-11.2086j], dtype=torch.cdouble)
_b = torch.cat((_b, _b.conj()))
_c = torch.tensor([2.2377-1.626j, 1.4652-1.7896j, 0.8393-1.892j, 0.2739-1.9418j], dtype=torch.cdouble)
_c = torch.cat((_c, -_c.conj()))

def wofz_torch(z: torch.Tensor) -> torch.Tensor:
    """
    Approximation rationnelle de W(z). Supporte cfloat/cdouble et batch arbitraire.
    """
    inv_sqrt_pi = 1.0 / math.sqrt(math.pi)
    # Assure dtype complexe
    if z.dtype not in (torch.complex64, torch.complex128):
        z = z.to(torch.complex128 if z.dtype == torch.float64 else torch.complex64)

    b = _b.to(device=z.device, dtype=z.dtype)
    c = _c.to(device=z.device, dtype=z.dtype)

    z_expanded = z.unsqueeze(-1)  # [..., 1]
    w = (b / (z_expanded - c)).sum(dim=-1) * (1j * inv_sqrt_pi)
    # symétrie pour Im(z)<0
    mask = (z.imag < 0)
    w_ref = torch.exp(-(z**2)) * 2.0 - w.conj()
    return torch.where(mask, w_ref, w)


def pine_profile_torch_complex(x, sigma_hwhm, gamma, gDicke, *, device='cpu'):
    """
    Retourne (réel, imag) du profil complex de Pine.
    S’assure que les largeurs sont positifs et non-nuls.
    """
    # dtype commun (float64 conseillé en amont)
    dtype = torch.promote_types(x.dtype, sigma_hwhm.dtype)
    dtype = torch.promote_types(dtype, gamma.dtype)
    x = x.to(device=device, dtype=dtype)
    sigma_hwhm = sigma_hwhm.to(device=device, dtype=dtype).clamp_min(torch.finfo(dtype).tiny)
    gamma = gamma.to(device=device, dtype=dtype).clamp_min(torch.finfo(dtype).tiny)
    gDicke = gDicke.to(device=device, dtype=dtype).clamp_min(torch.finfo(dtype).tiny)

    sigma = sigma_hwhm / math.sqrt(2*math.log(2.0))
    rt2ln2 = math.sqrt(math.log(2.0))
    xh = rt2ln2 * x / sigma_hwhm
    yh = rt2ln2 * gamma / sigma_hwhm
    zD = rt2ln2 * gDicke / sigma_hwhm

    z = xh.to(torch.float64) + 1j*(yh.to(torch.float64) + zD.to(torch.float64))
    k = -wofz_torch(z)  # complex64/128
    k_r, k_i = k.real.to(dtype), k.imag.to(dtype)

    root_pi = math.sqrt(math.pi)
    denom = (1 - zD*root_pi*k_r)**2 + (zD*root_pi*k_i)**2
    denom = denom.clamp_min(torch.finfo(dtype).tiny)

    real = (k_r - zD*root_pi*(k_r**2 + k_i**2)) / denom
    imag = k_i / denom
    factor = math.sqrt(math.log(2.0) / math.pi) / sigma
    return real * factor, imag * factor


def apply_line_mixing_complex(real_prof, imag_prof, lmf, nlmf, T, TREF=296.0):
    flm = lmf * ((T / TREF) ** nlmf)
    return real_prof + imag_prof * flm


def polyval_torch(coeffs: torch.Tensor, x: torch.Tensor) -> torch.Tensor:
    """
    coeffs: [B, K] avec a0,a1,...,a_{K-1}; x: [N] ou [B,N]
    Renvoie [B,N]
    """
    if x.ndim == 1:
        x = x.unsqueeze(0).expand(coeffs.size(0), -1)
    B, K = coeffs.shape
    N = x.shape[1]
    powers = torch.arange(K, device=x.device, dtype=x.dtype)  # aligne le dtype
    X = x.unsqueeze(1).pow(powers.view(-1, 1))  # [B,K,N]
    return (coeffs.unsqueeze(2) * X).sum(dim=1)  # [B,N]


def _is_preprocessed(transitions_dict: Dict[str, Any]) -> bool:
    # Heuristique : si pour une mol, on a des tenseurs directement au lieu de listes de dicts
    k = next(iter(transitions_dict))
    return isinstance(next(iter(transitions_dict[k].values())), torch.Tensor)

def batch_physics_forward_multimol_vgrid(
    sig0, dsig, poly_freq, v_grid_idx, baseline_coeffs,
    transitions_dict, P, T, mf_dict, device='cpu'
):
    """
    Compatible arrière :
      - transitions_dict peut être soit la version brute (listes de dicts),
        soit la version pré-tensorisée (dict de {field: tensor[L]}).
    """
    B = sig0.shape[0]
    N = v_grid_idx.shape[0]
    d64 = torch.float64

    v_grid_idx = v_grid_idx.to(device=device, dtype=d64)
    sig0 = sig0.to(device=device, dtype=d64).unsqueeze(1)
    dsig = dsig.to(device=device, dtype=d64).unsqueeze(1)
    P    = P.to(device=device, dtype=d64).unsqueeze(1)
    T    = T.to(device=device, dtype=d64).unsqueeze(1)

    if baseline_coeffs.dim() == 1:
        baseline_coeffs = baseline_coeffs.unsqueeze(0)
    baseline_coeffs = baseline_coeffs.to(device=device, dtype=d64)

    poly_freq_torch = torch.tensor(poly_freq, dtype=d64, device=device).unsqueeze(0).expand(B, -1)
    coeffs = torch.cat([sig0, dsig, poly_freq_torch], dim=1)
    v_grid_batch = polyval_torch(coeffs, v_grid_idx)  # [B,N]

    total_profile = torch.zeros((B, N), device=device, dtype=d64)

    # constantes (mises en cache par device/dtype)
    C, NA, KB, P0, T0, L0, TREF, tiny = _physics_constants(str(device), "float64")

    for mol, trans in transitions_dict.items():
        if _is_preprocessed(transitions_dict):
            amp   = trans['amplitude'].to(device=device, dtype=d64).view(1, -1, 1)
            center= trans['center'].to(device=device, dtype=d64).view(1, -1, 1)
            ga    = trans['gamma_air'].to(device=device, dtype=d64).view(1, -1, 1)
            gs    = trans['gamma_self'].to(device=device, dtype=d64).view(1, -1, 1)
            na    = trans['n_air'].to(device=device, dtype=d64).view(1, -1, 1)
            sa    = trans['shift_air'].to(device=device, dtype=d64).view(1, -1, 1)
            gd    = trans['gDicke'].to(device=device, dtype=d64).view(1, -1, 1)
            nd    = trans['nDicke'].to(device=device, dtype=d64).view(1, -1, 1)
            lmf   = trans['lmf'].to(device=device, dtype=d64).view(1, -1, 1)
            nlmf  = trans['nlmf'].to(device=device, dtype=d64).view(1, -1, 1)
        else:
            # chemin “ancien” (pas pré-tensorisé)
            amp, center, ga, gs, na, sa, gd, nd, lmf, nlmf = [
                torch.tensor([t[k] for t in trans], dtype=d64, device=device).view(1, -1, 1)
                for k in ['amplitude', 'center', 'gamma_air', 'gamma_self', 'n_air',
                          'shift_air', 'gDicke', 'nDicke', 'lmf', 'nlmf']
            ]

        mf = mf_dict[mol].to(device=device, dtype=d64).view(B, 1, 1)
        Mmol = torch.tensor(MOLECULE_PARAMS[mol]['M'], dtype=d64, device=device)
        PL   = torch.tensor(MOLECULE_PARAMS[mol]['PL'], dtype=d64, device=device)

        T_exp = T.view(B, 1, 1); P_exp = P.view(B, 1, 1)
        v_grid_exp = v_grid_batch.view(B, 1, N)

        x = v_grid_exp - center  # [B,L,N]

        sigma_HWHM = (center / C) * torch.sqrt((2 * NA * KB * T_exp * math.log(2.0)) / Mmol)
        sigma_HWHM = sigma_HWHM.clamp_min(tiny)

        gamma = (P_exp / P0) * (TREF / T_exp).pow(na) * (ga * (1 - mf) + gs * mf)
        gamma = gamma.clamp_min(tiny)

        real_prof, imag_prof = pine_profile_torch_complex(x, sigma_HWHM, gamma, gd, device=device)
        profile = apply_line_mixing_complex(real_prof, imag_prof, lmf, nlmf, T_exp, TREF=TREF)

        band = profile * amp * PL * 100.0 * mf * L0 * (P_exp / P0) * (T0 / T_exp)
        total_profile = total_profile + band.sum(dim=1)  # [B,N]

    transmission = torch.exp(-total_profile).clamp_min(tiny)

    x_bl = torch.arange(N, device=device, dtype=d64)
    powers_bl = torch.arange(baseline_coeffs.shape[1], device=device, dtype=d64)
    Xbl = x_bl.unsqueeze(0).pow(powers_bl.view(-1, 1))  # [K,N]
    baseline = (baseline_coeffs.unsqueeze(2) * Xbl.unsqueeze(0)).sum(dim=1).clamp_min(tiny)  # [B,N]

    return (transmission * baseline), v_grid_batch



# ============================================================
# 3) Bruits & Utils
# ============================================================
def add_noise_variety(spectra, *, generator=None, **cfg):
    std_add_range     = cfg.get("std_add_range", (0.001, 0.01))
    std_mult_range    = cfg.get("std_mult_range", (0.002, 0.02))
    p_drift           = cfg.get("p_drift", 0.7)
    drift_sigma_range = cfg.get("drift_sigma_range", (8.0, 90.0))
    drift_amp_range   = cfg.get("drift_amp_range", (0.002, 0.03))
    p_fringes         = cfg.get("p_fringes", 0.6)
    n_fringes_range   = cfg.get("n_fringes_range", (1, 3))
    fringe_freq_range = cfg.get("fringe_freq_range", (0.2, 12.0))
    fringe_amp_range  = cfg.get("fringe_amp_range", (0.001, 0.01))
    p_spikes          = cfg.get("p_spikes", 0.4)
    spikes_count_range= cfg.get("spikes_count_range", (1, 4))
    spike_amp_range   = cfg.get("spike_amp_range", (0.002, 0.03))
    spike_width_range = cfg.get("spike_width_range", (1.0, 4.0))
    clip              = cfg.get("clip", (0.0, 1.3))

    y = spectra
    B, N = y.shape[-2], y.shape[-1]
    dev, dtype = y.device, y.dtype
    g = generator

    def r(a, b):  return (torch.rand((), device=dev, generator=g) * (b - a) + a).item()
    def ri(a, b): return int(torch.randint(a, b + 1, (), device=dev, generator=g).item())
    def rbool(p): return bool(torch.rand((), device=dev, generator=g) < p)

    std_add  = r(*std_add_range)
    std_mult = r(*std_mult_range)
    add  = torch.randn(y.shape, device=dev, dtype=dtype, generator=g) * std_add
    add  = add - add.mean(dim=-1, keepdim=True)
    mult = 1.0 + torch.randn(y.shape, device=dev, dtype=dtype, generator=g) * std_mult
    mult = mult / mult.mean(dim=-1, keepdim=True)
    out = y * mult + add

    if rbool(p_drift):
        sigma = r(*drift_sigma_range)
        rad = max(1, int(3 * sigma))
        xk = torch.arange(-rad, rad + 1, device=dev, dtype=dtype)
        kernel = torch.exp(-0.5 * (xk / sigma) ** 2); kernel = kernel / kernel.sum()
        drift = torch.randn((B, N), device=dev, dtype=dtype, generator=g)
        drift = drift - drift.mean(dim=-1, keepdim=True)
        drift = F.pad(drift.unsqueeze(1), (rad, rad), mode="reflect")
        drift = F.conv1d(drift, kernel.view(1, 1, -1)).squeeze(1)
        drift = drift / (drift.std(dim=-1, keepdim=True) + 1e-8) * r(*drift_amp_range)
        out = out + drift

    if rbool(p_fringes):
        t = torch.linspace(0, 1, N, device=dev, dtype=dtype)
        fringes = torch.zeros((B, N), device=dev, dtype=dtype)
        for _ in range(ri(*n_fringes_range)):
            f, phi, amp = r(*fringe_freq_range), r(0.0, 2 * math.pi), r(*fringe_amp_range)
            fringes = fringes + amp * torch.sin(2 * math.pi * f * t + phi)
        out = out + fringes

    if rbool(p_spikes):
        grid = torch.arange(N, device=dev, dtype=dtype)
        spikes = torch.zeros((B, N), device=dev, dtype=dtype)
        for _ in range(ri(*spikes_count_range)):
            mu, width = r(0.0, N - 1.0), r(*spike_width_range)
            amp = r(*spike_amp_range) * (1.0 if rbool(0.5) else -1.0)
            spikes = spikes + amp * torch.exp(-0.5 * ((grid - mu) / width) ** 2)
        out = out + spikes

    if clip is not None:
        out = torch.clamp(out, *clip)
    return out


# ============================================================
# 4) Encodeur EfficientNet1D (baseline, patchable)
# ============================================================

# ==== TÊTE MLP: helpers ====
def _make_act(name: str):
    name = (name or "gelu").lower()
    if name == "relu": return nn.ReLU()
    if name == "silu": return nn.SiLU()
    if name == "tanh": return nn.Tanh()
    return nn.GELU()  # défaut

def _make_norm(name: str, dim: int):
    name = (name or "layer").lower()
    if name == "batch": return nn.BatchNorm1d(dim)
    if name == "none":  return nn.Identity()
    return nn.LayerNorm(dim)  # défaut


class SiLU(nn.Module):
    def forward(self, x): return x * torch.sigmoid(x)

class SqueezeExcitation1D(nn.Module):
    def __init__(self, in_channels, reduced_dim):
        super().__init__()
        self.se = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Conv1d(in_channels, reduced_dim, 1),
            SiLU(),
            nn.Conv1d(reduced_dim, in_channels, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.se(x)


class MBConv1DBlock(nn.Module):
    """
    MBConv 1D avec SE optionnel appliqué
    au chemin résiduel F(x) avant l'addition du skip.
    """
    def __init__(self, expand, depthwise, se, project, use_skip: bool):
        super().__init__()
        self.expand = expand
        self.depthwise = depthwise
        self.se = se
        self.project = project
        self.use_skip = use_skip

    def forward(self, x):
        identity = x
        x = self.expand(x) if not isinstance(self.expand, nn.Identity) else x
        x = self.depthwise(x)
        if self.se is not None:
            x = x * self.se(x)
        x = self.project(x)
        if self.use_skip:
            x = x + identity
        return x

class EfficientNetEncoder(nn.Module):
    """
    Encoder EfficientNet-like 1D avec GroupNorm robuste, SE.
    Expose .feat_dim et renvoie (features, None) en forward.
    """
    def __init__(
        self,
        in_channels: int = 1,
        width_mult: float = 1.0,
        depth_mult: float = 1.0,
        se_ratio: float = 0.25,
        group_norm_groups: int = 16,
        **kwargs,
    ):
        super().__init__()
        import math

        self.in_channels = int(in_channels)
        self.width_mult = float(width_mult)
        self.depth_mult = float(depth_mult)
        self.se_ratio = float(se_ratio)
        self.group_norm_groups = int(group_norm_groups)

        def round_filters(c):
            c = int(c * self.width_mult)
            return max(1, c)

        def round_repeats(r):
            from math import ceil
            return max(1, int(ceil(r * self.depth_mult)))

        def GN(channels: int) -> nn.GroupNorm:
            ch = int(channels)
            g = math.gcd(max(1, self.group_norm_groups), max(1, ch))
            if g <= 0: g = 1
            return nn.GroupNorm(g, ch)

        # Stem
        stem_out = round_filters(32)
        self.stem = nn.Sequential(
            nn.Conv1d(self.in_channels, stem_out, kernel_size=3, stride=2, padding=1, bias=False),
            GN(stem_out),
            nn.SiLU(inplace=True),
        )

        # (expand, c_out, repeats, k, stride, se_ratio)
        blocks_args = [
            (1,  16, 1, 3, 1, self.se_ratio),
            (6,  24, 2, 3, 2, self.se_ratio),
            (6,  40, 2, 5, 2, self.se_ratio),
            (6,  80, 3, 3, 2, self.se_ratio),
            (6, 112, 3, 5, 1, self.se_ratio),
            (6, 192, 4, 5, 2, self.se_ratio),
            (6, 320, 1, 3, 1, self.se_ratio),
        ]

        layers = []
        in_ch = stem_out
        for (exp, c_out, repeats, k, s, se) in blocks_args:
            c_out = round_filters(c_out)
            repeats = round_repeats(repeats)
            for i in range(repeats):
                stride = s if i == 0 else 1
                mid = round_filters(in_ch * exp)

                # expand 1x1 (sauté si exp==1)
                expand = nn.Sequential(
                    nn.Conv1d(in_ch, mid, kernel_size=1, bias=False),
                    GN(mid),
                    nn.SiLU(inplace=True),
                ) if exp != 1 else nn.Identity()

                # depthwise
                dw_in = mid if exp != 1 else in_ch
                depthwise = nn.Sequential(
                    nn.Conv1d(dw_in, dw_in, kernel_size=k, stride=stride, padding=k // 2,
                              groups=dw_in, bias=False),
                    GN(dw_in),
                    nn.SiLU(inplace=True),
                )

                # SE
                use_se = (se is not None) and (se > 0.0)
                if use_se:
                    se_in = dw_in
                    se_hidden = max(1, int(se_in * se))
                    se_block = SqueezeExcitation1D(se_in, se_hidden)
                else:
                    se_block = None

                # project 1x1
                project = nn.Sequential(
                    nn.Conv1d(dw_in, c_out, kernel_size=1, bias=False),
                    GN(c_out),
                )

                use_skip = (stride == 1 and in_ch == c_out)

                layers.append(
                    MBConv1DBlock(
                        expand=expand,
                        depthwise=depthwise,
                        se=se_block,
                        project=project,
                        use_skip=use_skip,
                    )
                )
                in_ch = c_out

        self.blocks = nn.Sequential(*layers)

        # Head
        head_out = round_filters(1280)
        self.head = nn.Sequential(
            nn.Conv1d(in_ch, head_out, kernel_size=1, bias=False),
            GN(head_out),
            nn.SiLU(inplace=True),
        )

        self.feat_dim = head_out  # dimension des features canalisées

    def forward(self, x):
        # x: [B, C=1, N]
        x = self.stem(x)
        x = self.blocks(x)
        x = self.head(x)
        return x, None

# ============================================================
# 5) ReLoBRaLo pour pondérer dynamiquement
# ============================================================
class ReLoBRaLoLoss:
    def __init__(self, loss_names, alpha=0.9, tau=1.0, history_len=10):
        self.loss_names = list(loss_names)
        self.alpha = alpha; self.tau = tau; self.history_len = history_len
        self.loss_history = {name: [] for name in loss_names}
        self.weights = torch.ones(len(loss_names), dtype=torch.float32)
        
    def compute_weights(self, current_losses: torch.Tensor):
        for i, name in enumerate(self.loss_names):
            self.loss_history[name].append(float(current_losses[i].detach().cpu()))
            if len(self.loss_history[name]) > self.history_len:
                self.loss_history[name].pop(0)
        if len(self.loss_history[self.loss_names[0]]) < 2:
            return self.weights.to(current_losses.device)
        relative = []
        for name in self.loss_names:
            hist = self.loss_history[name]
            j = random.randint(0, len(hist) - 2)
            ratio = hist[-1] / (hist[j] + 1e-8)
            relative.append(ratio)
        relative = torch.tensor(relative, dtype=torch.float32, device=current_losses.device)
        mean_rel = relative.mean()
        balancing = mean_rel / (relative + 1e-8)
        new_w = len(self.loss_names) * torch.softmax(balancing / self.tau, dim=0)
        self.weights = (self.alpha * self.weights.to(current_losses.device) +
                        (1 - self.alpha) * new_w).detach()
        return self.weights.to(current_losses.device)

# ============================================================
# 6) Raffineur EfficientNet (identique au backbone)
# ============================================================
class EfficientNetRefiner(nn.Module):

    """
    Raffineur qui prend (noisy, resid, params_pred_norm, cond_norm, feat_shared)
    et renvoie un delta normalisé de taille [B, m_params].
    Le cœur est un petit EfficientNetEncoder sur 2 canaux (noisy & resid),
    puis concat avec les features du backbone, la condition FiLM et la prédiction courante.
    """

    def __init__(
        self,
        m_params: int,
        cond_dim: int,
        backbone_feat_dim: int,
        delta_scale: float = 0.1,
        enc_kwargs: Optional[dict] = None,
    ):
        super().__init__()
        enc_kwargs = dict(enc_kwargs or {})
        self.delta_scale = float(delta_scale)
        self.m_params = int(m_params)
        self.cond_dim = int(cond_dim)
        self.backbone_feat_dim = int(backbone_feat_dim)
        self.use_film = True

        # encodeur 1D sur (noisy,resid)
        self.enc = EfficientNetEncoder(in_channels=2, **enc_kwargs)

        # tête MLP sur le vecteur concaténé
        in_vec = self.enc.feat_dim + self.backbone_feat_dim + self.m_params + self.cond_dim
        hidden = max(128, in_vec // 2)
        self.head = nn.Sequential(
            nn.Linear(in_vec, hidden),
            nn.LayerNorm(hidden),
            nn.GELU(),
            nn.Linear(hidden, hidden),
            nn.LayerNorm(hidden),
            nn.GELU(),
            nn.Linear(hidden, self.m_params),
        )

    def forward(self, noisy: torch.Tensor, resid: torch.Tensor,
                params_pred_norm: torch.Tensor,
                cond_norm: Optional[torch.Tensor],
                feat_shared: torch.Tensor) -> torch.Tensor:
        """
        noisy/resid: [B, N]
        params_pred_norm: [B, m_params]
        cond_norm: [B, cond_dim] ou None
        feat_shared: [B, backbone_feat_dim]
        """
        # encoder (noisy, resid)
        x = torch.stack([noisy, resid], dim=1)        # [B,2,N]
        feat_map, _ = self.enc(x)                     # [B, C', N']
        pooled = F.adaptive_avg_pool1d(feat_map, 1).squeeze(-1)  # [B, C']

        pieces = [pooled, feat_shared, params_pred_norm]
        if cond_norm is not None and self.cond_dim > 0:
            pieces.append(cond_norm)
        h = torch.cat(pieces, dim=1)                  # [B, in_vec]

        delta = torch.tanh(self.head(h)) * self.delta_scale
        return delta




# ============================================================
# 7) Modèle principal Lightning (Étape A/B générique)
# ============================================================
class PhysicallyInformedAE(pl.LightningModule):
    def __init__(self, 
                 n_points: int, param_names: List[str], poly_freq_CH4, transitions_dict,
                 lr: float = 1e-4, alpha_param: float = 1.0, alpha_phys: float = 1.0,
                 head_mode: str = "multi", predict_params: Optional[List[str]] = None,
                 film_params: Optional[List[str]] = None,
                 refine_steps: int = 1, refine_delta_scale: float = 0.1, refine_target: str = "noisy",
                 refine_warmup_epochs: int = 30, freeze_base_epochs: int = 50,
                 base_lr: float = None, refiner_lr: float = None, recon_max1: bool = True,
                 corr_mode: str = "none",  corr_savgol_win: int = 15, corr_savgol_poly: int = 3,
                 weight_mf: float = 1.0, gas: str = "CH4",
                 width_mult: float = 1.0, depth_mult: float = 1.0,
                 ref_width_mult: Optional[float] = None, ref_depth_mult: Optional[float] = None,
                 se_ratio: float = 0.25, 
                 group_norm_groups: int = 8,
                 head_hidden_mult: float = 0.5,
                 head_hidden_min: int = 128,
                 head_layers: int = 2,
                 head_dropout: float = 0.0,
                 head_activation: str = "gelu",
                 head_norm: str = "layer"):

        super().__init__()
        self.save_hyperparameters(ignore=["transitions_dict", "poly_freq_CH4"])
        self.param_names = list(param_names)
        self.n_params = len(self.param_names)
        self.n_points = int(n_points)
        self.poly_freq_CH4 = poly_freq_CH4
        self.transitions_dict = transitions_dict
        self.gas = gas.upper()

        # pertes
        self.lr = float(lr)
        self.base_lr = float(base_lr) if base_lr is not None else float(lr)
        self.refiner_lr = float(refiner_lr) if refiner_lr is not None else float(lr)
        self.alpha_param = float(alpha_param)
        self.alpha_phys = float(alpha_phys)
        self.weight_mf = float(weight_mf)

        # corr/derivative
        self.corr_mode = str(corr_mode).lower()
        self.corr_savgol_win = int(corr_savgol_win)
        self.corr_savgol_poly = int(corr_savgol_poly)

        # FiLM
        if predict_params is None:
            predict_params = self.param_names
        self.predict_params = list(predict_params)
        self.provided_params = [p for p in self.param_names if p not in self.predict_params]
        self.name_to_idx = {n: i for i, n in enumerate(self.param_names)}

        # après self.predict_params etc.
        self.relobralo_params = ReLoBRaLoLoss(
            loss_names=self.predict_params,  # même ordre que per_param
            alpha=0.9,        # lissage EMA
            tau=1.0,          # température softmax
            history_len=10,   # fenêtres d’historique
        )


        if film_params is None:
            self.film_params = list(self.provided_params)
        else:
            self.film_params = list(film_params)

        # ----- backbone EfficientNet-1D (noisy -> features)
        self.backbone = EfficientNetEncoder(
            in_channels=1,
            width_mult=width_mult,
            depth_mult=depth_mult,
            se_ratio=se_ratio,
            group_norm_groups=group_norm_groups,
        )
        self.feature_head = nn.Sequential(nn.AdaptiveAvgPool1d(1), nn.Flatten())
        feat_dim = self.backbone.feat_dim

        # ----- hyperparamètres de tête (avec défauts raisonnables) -----
        def _hp(name, default):
            return getattr(self.hparams, name, default)

        head_mode        = str(_hp("head_mode", "multi")).lower()
        head_hidden_mult = float(_hp("head_hidden_mult", 0.5))
        head_hidden_min  = int(_hp("head_hidden_min", 128))
        head_layers      = int(_hp("head_layers", 2))
        head_dropout     = float(_hp("head_dropout", 0.0))
        head_activation  = str(_hp("head_activation", "gelu"))
        head_norm        = str(_hp("head_norm", "layer"))

        H = max(head_hidden_min, int(round(feat_dim * head_hidden_mult)))
        act = _make_act(head_activation)
        def _norm(dim): 
            return _make_norm(head_norm, dim)

        # ----- shared MLP (profondeur variable) -----
        blocks = [nn.Linear(feat_dim, H), _norm(H), act]
        if head_dropout > 0: blocks.append(nn.Dropout(head_dropout))
        for _ in range(max(0, head_layers - 1)):
            blocks += [nn.Linear(H, H), _norm(H), act]
            if head_dropout > 0: blocks.append(nn.Dropout(head_dropout))
        self.shared_head = nn.Sequential(*blocks)

        # ----- FiLM (recréée ici, avant toute utilisation) -----
        self.cond_dim = len(self.film_params)
        self.use_film = True
        if self.cond_dim > 0:
            self.film = nn.Sequential(
                nn.Linear(self.cond_dim, H), nn.Tanh(), nn.Linear(H, 2 * H)
            )
            # masque activable/désactivable par set_film_subset
            self.register_buffer("film_mask", torch.ones(self.cond_dim))
        else:
            self.film = None
            self.film_mask = None

        # ----- sorties -----
        self.head_mode = head_mode
        if self.head_mode == "single":
            self.out_head = nn.Linear(H, len(self.predict_params))
        else:
            self.out_heads = nn.ModuleDict({p: nn.Linear(H, 1) for p in self.predict_params})


        # ----- raffineur EfficientNet-1D (noisy,resid -> delta params)
        if int(refine_steps) <= 0:
            # Étape A pure : pas de raffineur instancié 
            self.refiner = None
        else:
            ref_wm = ref_width_mult if ref_width_mult is not None else width_mult
            ref_dm = ref_depth_mult if ref_depth_mult is not None else depth_mult
            enc_kwargs_ref = dict(
                width_mult=ref_wm,
                depth_mult=ref_dm,
                se_ratio=se_ratio,
                group_norm_groups=group_norm_groups,
            )
            self.refiner = EfficientNetRefiner(
                m_params=len(self.predict_params),
                cond_dim=self.cond_dim,
                backbone_feat_dim=self.backbone.feat_dim,
                delta_scale=refine_delta_scale,
                enc_kwargs=enc_kwargs_ref,
            )

        # stages (A/B)
        self.refine_steps = int(refine_steps)
        self.refine_target = str(refine_target).lower()
        self.refine_warmup_epochs = int(refine_warmup_epochs)
        self.freeze_base_epochs = int(freeze_base_epochs)

        # autres    
        self.recon_max1 = bool(recon_max1)

        # overrides stage
        self._override_stage: Optional[str] = None
        self._override_refine_steps: Optional[int] = None
        self._override_delta_scale: Optional[float] = None


    # ========= helpers / FiLM / stage control =========
    def set_film_usage(self, use: bool = True):
        self.use_film = bool(use)
        if hasattr(self, "refiner"):
            self.refiner.use_film = bool(use)

    def set_film_subset(self, names=None):
        if self.cond_dim == 0 or self.film_mask is None:
            return
        if names is None or names == "all":
            mask = torch.ones(self.cond_dim, device=self.film_mask.device)
        else:
            names = set(names)
            mask = torch.zeros(self.cond_dim, device=self.film_mask.device)
            for i, n in enumerate(self.film_params):
                if n in names:
                    mask[i] = 1.0
        self.film_mask.copy_(mask)

    def set_stage_mode(self, mode: Optional[str], refine_steps: Optional[int] = None, delta_scale: Optional[float] = None):
        if mode is not None:
            mode = mode.upper()
            assert mode in {"A", "B1", "B2"}
        self._override_stage = mode
        if refine_steps is not None:
            self.refine_steps = int(refine_steps)
        if delta_scale is not None and self.refiner is not None:
            self.refiner.delta_scale = float(delta_scale)

    # ========= feature → params =========
    def _predict_params_from_features(self, feat: torch.Tensor, cond_norm: Optional[torch.Tensor] = None) -> torch.Tensor:
        h = self.shared_head(feat)
        if self.film is not None and cond_norm is not None and self.use_film:
            cm = cond_norm if (self.film_mask is None or self.film_mask.numel() != cond_norm.shape[1]) \
                 else cond_norm * self.film_mask.unsqueeze(0)
            gb = self.film(cm)  # [B, 2H]
            H = h.shape[1]
            gamma, beta = gb[:, :H], gb[:, H:]
            h = h * (1 + 0.1 * gamma) + 0.1 * beta
        if self.head_mode == "single":
            y = self.out_head(h)
        else:
            y = torch.cat([self.out_heads[p](h) for p in self.predict_params], dim=1)
        return torch.sigmoid(y).clamp(1e-4, 1 - 1e-4)

    def encode(self, spectra: torch.Tensor, pooled: bool = True, detach: bool = False):
        latent, _ = self.backbone(spectra.unsqueeze(1))
        feat = self.feature_head(latent) if pooled else latent
        return feat.detach() if detach else feat

    def _denorm_params_subset(self, y_norm_subset: torch.Tensor, names: List[str]) -> torch.Tensor:
        cols = [unnorm_param_torch(n, y_norm_subset[:, i]) for i, n in enumerate(names)]
        return torch.stack(cols, dim=1)

    def _compose_full_phys(self, pred_phys: torch.Tensor, provided_phys_tensor: torch.Tensor) -> torch.Tensor:
        B = pred_phys.shape[0]
        full = pred_phys.new_empty((B, self.n_params))
        for j, idx in enumerate([self.name_to_idx[p] for p in self.predict_params]):
            full[:, idx] = pred_phys[:, j]
        for j, idx in enumerate([self.name_to_idx[p] for p in self.provided_params]):
            full[:, idx] = provided_phys_tensor[:, j]
        return full

    def _physics_reconstruction(self, y_phys_full: torch.Tensor, device, scale: Optional[torch.Tensor] = None):
        p = {k: y_phys_full[:, i] for i, k in enumerate(self.param_names)}
        v_grid_idx = torch.arange(self.n_points, dtype=torch.float64, device=device)

        # --- CHANGEMENT ICI : indices explicites ---
        bl_names = ['baseline0','baseline1','baseline2']
        bl_cols  = [self.name_to_idx[n] for n in bl_names]
        baseline_coeffs = y_phys_full[:, bl_cols]

        spectra, _ = batch_physics_forward_multimol_vgrid(
            p['sig0'], p['dsig'], self.poly_freq_CH4, v_grid_idx,
            baseline_coeffs, self.transitions_dict, p['P'], p['T'], {self.gas: p[f'mf_{self.gas}']}, device=device
        )
        spectra = spectra.to(torch.float32)
        if self.recon_max1:
            maxv = spectra.amax(dim=1, keepdim=True).clamp_min(1e-9)
            spectra = spectra / maxv
        return spectra


    # ========= Savitzky–Golay & corr =========
    def _savgol_coeffs(self, window_length: int, polyorder: int, deriv: int = 1, delta: float = 1.0,
                       device=None, dtype=torch.float64) -> torch.Tensor:
        W = int(window_length)
        P = int(polyorder)
        if W % 2 == 0: W += 1
        W = max(3, W)
        P = min(P, W - 1)
        m = (W - 1) // 2
        dev = device or self.device
        x = torch.arange(-m, m + 1, device=dev, dtype=dtype)
        A = torch.stack([x ** j for j in range(P + 1)], dim=1)
        pinv = torch.linalg.pinv(A)
        coeff = math.factorial(deriv) * pinv[deriv, :] / (delta ** deriv)
        return coeff.to(dtype=torch.float32)

    def _savgol_deriv(self, y: torch.Tensor, window_length: int, polyorder: int, deriv: int = 1) -> torch.Tensor:
        B, N = y.shape
        W = int(window_length)
        if W % 2 == 0: W += 1
        if W > N: W = N if N % 2 == 1 else (N - 1)
        W = max(3, W)
        P = min(int(polyorder), W - 1)
        coeff = self._savgol_coeffs(W, P, deriv=deriv, device=y.device, dtype=torch.float64).view(1, 1, -1)
        pad = (W - 1) // 2
        y1 = F.pad(y.unsqueeze(1), (pad, pad), mode="reflect")
        return F.conv1d(y1, coeff).squeeze(1)

    def _dx(self, y: torch.Tensor) -> torch.Tensor:
        d = 0.5 * (y[:, 2:] - y[:, :-2])
        return torch.cat([d[:, :1], d, d[:, -1:]], dim=1)

    def _pearson_corr_loss(self, y_hat: torch.Tensor, y: torch.Tensor,
                           derivative: str | bool = False,
                           savgol_win: int = 11, savgol_poly: int = 3, eps: float = 1e-8) -> torch.Tensor:
        mode = derivative
        if isinstance(mode, bool):
            mode = "central" if mode else "none"
        mode = (mode or "none").lower()
        if mode == "central":
            y_hat = self._dx(y_hat); y = self._dx(y)
        elif mode in ("savgol", "sg", "savitzky_golay", "savitzky-golay"):
            y_hat = self._savgol_deriv(y_hat, savgol_win, savgol_poly, 1)
            y     = self._savgol_deriv(y,     savgol_win, savgol_poly, 1)
        y_hat = y_hat.float(); y = y.float()
        yhc = y_hat - y_hat.mean(dim=1, keepdim=True)
        yc  = y - y.mean(dim=1, keepdim=True)
        num = (yhc * yc).sum(dim=1)
        den = torch.sqrt((yhc.pow(2).sum(dim=1) + eps) * (yc.pow(2).sum(dim=1) + eps))
        corr = num / den
        return (1.0 - corr).mean()

    # ========= training / validation =========
    def _common_step(self, batch, tag: str):
        dev = self.device

        # --- 0) Déballage/placement sur device ---
        params_phys = batch["params_phys"].to(dev, non_blocking=True)   # [B,8] physiques
        params_true_norm = batch["params"].to(dev, non_blocking=True)   # [B,8] normalisés
        baseline_coeffs = batch["baseline_coeffs"].to(dev, non_blocking=True)  # [B,3]
        B = params_phys.size(0)

        # mapping indices cohérent avec self.param_names
        n2i = self.name_to_idx
        sig0 = params_phys[:, n2i["sig0"]]
        dsig = params_phys[:, n2i["dsig"]]
        P    = params_phys[:, n2i["P"]]
        T    = params_phys[:, n2i["T"]]
        mf   = params_phys[:, n2i[f"mf_{self.gas}"]]

        # grille d'indices
        N = int(batch["num_points"][0].item())
        v_grid_idx = torch.arange(N, dtype=torch.float64, device=dev)

        # --- 1) Physique "clean" (vectorisée GPU) ---
        spectra_clean, _ = batch_physics_forward_multimol_vgrid(
            sig0.to(torch.float64), dsig.to(torch.float64),
            self.poly_freq_CH4, v_grid_idx,
            baseline_coeffs.to(torch.float64),
            self.transitions_dict, P.to(torch.float64), T.to(torch.float64),
            {self.gas: mf.to(torch.float64)}, device=dev
        )
        spectra_clean = spectra_clean.to(torch.float32)

        # --- 2) Bruit (GPU) ---
        if tag == "train":
            with_noise = getattr(self, "with_noise_train", True)
            noise_profile = getattr(self, "train_noise_profile", {})
        else:
            with_noise = getattr(self, "with_noise_val", False)
            noise_profile = getattr(self, "val_noise_profile", {})

        if with_noise:
            # bruit *indépendant par sample* (générateur par ligne)
            seeds = batch["noise_seed"].tolist()
            noisy_list = []
            for i in range(B):
                g = torch.Generator(device=dev)
                g.manual_seed(int(seeds[i]))
                noisy_list.append(add_noise_variety(spectra_clean[i:i+1], generator=g, **noise_profile))
            spectra_noisy = torch.cat(noisy_list, dim=0)
        else:
            spectra_noisy = spectra_clean

        # --- 3) Mise à l’échelle d’entrée (comme avant, mais GPU) ---
        scale_noisy = lowess_firstN_start_value(spectra_noisy, Nwin=20).unsqueeze(1).clamp_min(1e-8)
        noisy = (spectra_noisy / scale_noisy).to(torch.float32)

        # cible clean normalisée à son max (cohérent)
        max_clean = spectra_clean.amax(dim=1, keepdim=True).clamp_min(1e-8)
        clean = (spectra_clean / max_clean).to(torch.float32)

        # --- 4) FiLM cond (à partir des *vraies* valeurs normalisées) ---
        cond_norm = None
        if len(self.film_params) > 0:
            cols = [params_true_norm[:, self.name_to_idx[n]] for n in self.film_params]
            cond_norm = torch.stack(cols, dim=1)

        # --- 5) Passe A : features + tête(s) ---
        latent, _ = self.backbone(noisy.unsqueeze(1))
        feat_shared = self.feature_head(latent)
        params_pred_norm = self._predict_params_from_features(feat_shared, cond_norm)

        # --- 6) Paramètres fournis (non prédits) ---
        if len(self.provided_params) > 0:
            provided_cols = [params_true_norm[:, self.name_to_idx[n]] for n in self.provided_params]
            provided_norm_tensor = torch.stack(provided_cols, dim=1)
            provided_phys_tensor = self._denorm_params_subset(provided_norm_tensor, self.provided_params)
        else:
            provided_phys_tensor = params_pred_norm.new_zeros((noisy.shape[0], 0))

        # --- 7) Étape de raffinement (si actif) ---
        e = self.current_epoch
        target_for_resid = noisy if self.refine_target == "noisy" else clean
        effective_refine = 0 if e < self.refine_warmup_epochs else self.refine_steps
        if self._override_stage is not None:
            effective_refine = 0 if self._override_stage == "A" else self.refine_steps

        if (self.refiner is not None) and (effective_refine > 0):
            for _ in range(effective_refine):
                pred_phys  = self._denorm_params_subset(params_pred_norm, self.predict_params)
                y_full     = self._compose_full_phys(pred_phys, provided_phys_tensor)
                recon      = self._physics_reconstruction(y_full, clean.device, scale=None)
                resid      = recon - target_for_resid
                delta = self.refiner(noisy, resid, params_pred_norm, cond_norm, feat_shared)
                params_pred_norm = (params_pred_norm + delta).clamp(1e-4, 1 - 1e-4)

        # --- 8) Reconstruction physique finale & pertes ---
        pred_phys  = self._denorm_params_subset(params_pred_norm, self.predict_params)
        y_full     = self._compose_full_phys(pred_phys, provided_phys_tensor)
        recon      = self._physics_reconstruction(y_full, clean.device, scale=None)

        loss_phys_mse   = F.mse_loss(recon, clean)
        loss_phys_huber = F.smooth_l1_loss(recon, clean, beta=0.002)
        loss_phys       = 0.5 * loss_phys_mse + 0.5 * loss_phys_huber
        loss_corr       = self._pearson_corr_loss(
            recon, clean,
            derivative=(self.corr_mode if self.corr_mode != "none" else False),
            savgol_win=self.corr_savgol_win, savgol_poly=self.corr_savgol_poly
        )

        per_param_losses = []
        for j, name in enumerate(self.predict_params):
            true_j = params_true_norm[:, self.name_to_idx[name]]
            loss_j = F.mse_loss(params_pred_norm[:, j], true_j)
            if name == f"mf_{self.gas}":
                loss_j = self.weight_mf * loss_j
            per_param_losses.append(loss_j)

        if per_param_losses:
            per_param_losses = torch.stack(per_param_losses)
            w = self.relobralo_params.compute_weights(per_param_losses.detach())
            loss_params = (w * per_param_losses).sum() / (w.sum() + 1e-8)
        else:
            loss_params = torch.tensor(0.0, device=clean.device)

        loss = self.alpha_phys * (loss_phys + loss_corr) + self.alpha_param * loss_params

        self.log(f"{tag}_loss",   loss,       on_epoch=True, prog_bar=(tag == "val"), sync_dist=True)
        self.log(f"{tag}_phys",   loss_phys,  on_epoch=True, sync_dist=True)
        self.log(f"{tag}_corr",   loss_corr,  on_epoch=True, sync_dist=True)
        self.log(f"{tag}_params", loss_params,on_epoch=True, sync_dist=True)
        return loss


    def training_step(self, batch, _): return self._common_step(batch, "train")
    def validation_step(self, batch, _): self._common_step(batch, "val")

    def on_train_epoch_start(self):
        # Si pas de raffineur du tout → on entraîne toujours le backbone/heads (Stage A pur)
        if self.refiner is None or self.refine_steps <= 0:
            for m in [self.backbone, self.shared_head, getattr(self, "out_head", None),
                    getattr(self, "out_heads", None), self.film]:
                if m is None: 
                    continue
                for p in m.parameters():
                    p.requires_grad_(True)
            return

        # Raffineur présent : gérer A/B1/B2 + override
        if self._override_stage == "A":
            # Stage A (backbone+heads only)
            for p in self.refiner.parameters():
                p.requires_grad_(False)
            for m in [self.backbone, self.shared_head, getattr(self, "out_head", None),
                    getattr(self, "out_heads", None), self.film]:
                if m is None: 
                    continue
                for p in m.parameters():
                    p.requires_grad_(True)
            return

        if self._override_stage in {"B1", "B2"}:
            # B1: refiner only (A gelé) ; B2: tout trainable
            if self._override_stage == "B1":
                for p in self.refiner.parameters():
                    p.requires_grad_(True)
                for m in [self.backbone, self.shared_head, getattr(self, "out_head", None),
                        getattr(self, "out_heads", None), self.film]:
                    if m is None: 
                        continue
                    for p in m.parameters():
                        p.requires_grad_(False)
            else:  # B2
                for p in self.refiner.parameters():
                    p.requires_grad_(True)
                for m in [self.backbone, self.shared_head, getattr(self, "out_head", None),
                        getattr(self, "out_heads", None), self.film]:
                    if m is None: 
                        continue
                    for p in m.parameters():
                        p.requires_grad_(True)
            return

        # Pas d’override : scheduler normal (warmup A → B1 → B2)
        e = self.current_epoch
        if e < self.refine_warmup_epochs:
            # Stage A
            for p in self.refiner.parameters():
                p.requires_grad_(False)
            for m in [self.backbone, self.shared_head, getattr(self, "out_head", None),
                    getattr(self, "out_heads", None), self.film]:
                if m is None: 
                    continue
                for p in m.parameters():
                    p.requires_grad_(True)
        elif e < self.freeze_base_epochs:
            # Stage B1 (refiner only)
            for p in self.refiner.parameters():
                p.requires_grad_(True)
            for m in [self.backbone, self.shared_head, getattr(self, "out_head", None),
                    getattr(self, "out_heads", None), self.film]:
                if m is None: 
                    continue
                for p in m.parameters():
                    p.requires_grad_(False)
        else:
            # Stage B2 (joint finetune)
            for p in self.refiner.parameters():
                p.requires_grad_(True)
            for m in [self.backbone, self.shared_head, getattr(self, "out_head", None),
                    getattr(self, "out_heads", None), self.film]:
                if m is None: 
                    continue
                for p in m.parameters():
                    p.requires_grad_(True)



    def configure_optimizers(self):
        # groupe "base" (toujours)
        base_params = list(self.backbone.parameters()) + list(self.shared_head.parameters())
        if hasattr(self, "out_head") and self.out_head is not None:
            base_params += list(self.out_head.parameters())
        if hasattr(self, "out_heads") and self.out_heads is not None:
            base_params += list(self.out_heads.parameters())
        if getattr(self, "film", None) is not None:
            base_params += list(self.film.parameters())

        param_groups = [{"params": base_params, "lr": self.base_lr}]

        # groupe "refiner" seulement s’il existe ET doit être entraîné
        if self.refiner is not None and self.refine_steps > 0:
            param_groups.append({"params": self.refiner.parameters(), "lr": self.refiner_lr})

        opt = torch.optim.AdamW(param_groups, weight_decay=1e-4)
        sch = torch.optim.lr_scheduler.CosineAnnealingLR(
            opt, T_max=(self.trainer.max_epochs if self.trainer is not None else 100), eta_min=1e-8
        )
        return {"optimizer": opt, "lr_scheduler": sch}

    @torch.no_grad()
    def infer(self, spectra: torch.Tensor, provided_phys: dict, *, refine: bool = True, resid_target: str = "input"):
        self.eval()
        device = spectra.device
        B = spectra.shape[0]

        # condition FiLM
        if len(self.film_params) > 0:
            cols = [norm_param_torch(n, provided_phys[n].to(device)).unsqueeze(1) for n in self.film_params]
            cond_norm = torch.cat(cols, dim=1).to(torch.float32)
        else:
            cond_norm = None

        # passe A
        latent, _ = self.backbone(spectra.unsqueeze(1))
        feat_shared = self.feature_head(latent)
        params_pred_norm = self._predict_params_from_features(feat_shared, cond_norm)

        # phys fournis (non prédits)
        if len(self.provided_params) > 0:
            provided_list = [provided_phys[n].to(device) for n in self.provided_params]
            provided_phys_tensor = torch.stack(provided_list, dim=1)
        else:
            provided_phys_tensor = params_pred_norm.new_zeros((B, 0))

        spectra_target = spectra if resid_target in ("input", "noisy") else None

        # raffinement optionnel
        if refine and (self.refiner is not None) and (self.refine_steps > 0):
            for _ in range(self.refine_steps):
                pred_phys = self._denorm_params_subset(params_pred_norm, self.predict_params)
                y_full    = self._compose_full_phys(pred_phys, provided_phys_tensor)
                recon     = self._physics_reconstruction(y_full, device, None)
                if spectra_target is None:
                    break
                resid = recon - spectra_target
                delta = self.refiner(spectra, resid, params_pred_norm, cond_norm, feat_shared)
                params_pred_norm = params_pred_norm.add(delta).clamp(1e-4, 1-1e-4)

        pred_phys = self._denorm_params_subset(params_pred_norm, self.predict_params)
        y_full    = self._compose_full_phys(pred_phys, provided_phys_tensor)
        recon     = self._physics_reconstruction(y_full, device, None)
        return {"params_pred_norm": params_pred_norm, "y_phys_full": y_full, "spectra_recon": recon}


# ============================================================
# 8) Dataset synthétique + bruit
# ============================================================
class SpectraDataset(Dataset):
    """
    Il échantillonne des paramètres physiques (non normalisés), calcule leurs
    versions normalisées pour la supervision, et fournit un seed de bruit.
    Tout le gros calcul (physique + bruit) est fait sur GPU dans training_step.
    """
    def __init__(self, *, n_samples: int, num_points: int, gas: str,
                 poly_freq: List[float], transitions_dict: Dict[str, list],
                 sample_ranges: Dict[str, Tuple[float, float]],
                 with_noise: bool, noise_profile: dict,
                 freeze_noise: bool = False):
        super().__init__()
        self.n_samples = int(n_samples)
        self.num_points = int(num_points)
        self.gas = gas.upper()
        self.poly_freq = list(poly_freq)
        self.transitions_dict = transitions_dict   # laissé pour compat
        self.sample_ranges = dict(sample_ranges)
        self.with_noise = bool(with_noise)
        self.noise_profile = dict(noise_profile or {})
        self.freeze_noise = bool(freeze_noise)
        self.epoch = 0

        # cohérence bornes
        for k, (a, b) in self.sample_ranges.items():
            aa, bb = NORM_PARAMS[k]
            if not (aa <= a <= b <= bb):
                raise ValueError(f"sample_ranges[{k}]={a,b} hors de NORM_PARAMS={aa,bb}")

        # ordre de sortie (cohérent avec param_names du modèle)
        self.param_names = ['sig0', 'dsig', f'mf_{self.gas}', 'baseline0', 'baseline1', 'baseline2', 'P', 'T']

    def set_epoch(self, e: int):
        self.epoch = int(e)

    def _seed_for(self, idx: int) -> int:
        # seed stable par (epoch, idx) si freeze_noise=False ; fixe si True
        base = 1337 if self.freeze_noise else (torch.initial_seed() & 0x7FFFFFFFFFFFFFFF)
        return int((base + 1_000_003 * self.epoch + 97 * idx) % (2**63 - 1))

    def __len__(self): return self.n_samples

    def __getitem__(self, idx: int):
        # 1) échantillonne params physiques (CPU)
        vals = {k: random.uniform(*self.sample_ranges[k]) for k in self.param_names}

        # 2) versions torch (physiques) dans l'ordre PARAMS (CPU)
        params_phys = torch.tensor([vals[k] for k in self.param_names], dtype=torch.float32)  # [8]

        # 3) normalisés [0,1] pour la tête
        params_norm = torch.tensor(
            [norm_param_value(k, vals[k]) for k in self.param_names],
            dtype=torch.float32
        )

        # 4) baseline coeffs (CPU)
        baseline_coeffs = torch.tensor([vals['baseline0'], vals['baseline1'], vals['baseline2']], dtype=torch.float32)

        # 5) seed de bruit par sample
        noise_seed = torch.tensor(self._seed_for(idx), dtype=torch.int64)

        return {
            # POUR GPU STEP
            "params_phys": params_phys,           # [8] physiques (sig0, dsig, mf, b0,b1,b2,P,T)
            "params": params_norm,                # [8] normalisés (supervision)
            "baseline_coeffs": baseline_coeffs,   # [3]
            "noise_seed": noise_seed,             # int64
            # méta
            "num_points": torch.tensor(self.num_points, dtype=torch.int32),
        }

def collate_fn(samples):
    # collate simple, CPU-only
    keys = samples[0].keys()
    out = {}
    for k in keys:
        out[k] = torch.utils.data.default_collate([s[k] for s in samples])
    return out


# --- constants (au début de ton fichier) ---
ALL_TARGETS: tuple[str, ...] = (
    "sig0", "dsig", "mf_CH4", "P", "T", "baseline1", "baseline2"
)

def get_predict_list_A(cfg: dict | None = None) -> list[str]:
    pl = list(cfg.get("predict_list") or ALL_TARGETS)
    film_list = set(cfg.get("film_list") or [])
    pl = [p for p in pl if p not in film_list]
    return pl


# ============================================================
# 9) Callbacks utilitaires & évaluation
# ============================================================
class UpdateEpochInDataset(pl.Callback):
    def on_train_epoch_start(self, trainer, pl_module):
        try:
            ds = trainer.train_dataloader.dataset
        except Exception:
            ds = None
        if hasattr(ds, "set_epoch"):
            ds.set_epoch(trainer.current_epoch)


class EpochMetricsLogger(pl.Callback):
    """Callback Lightning pour logguer métriques d'époque dans un fichier ``.out``."""

    def __init__(self, log_path: str, *, rank_zero_only: bool = True):
        super().__init__()
        self.log_path = log_path
        self.rank_zero_only = rank_zero_only
        self._file_initialized = False

    def _is_allowed(self, trainer) -> bool:
        if not self.rank_zero_only:
            return True
        return getattr(trainer, "is_global_zero", True)

    def _prepare_file(self):
        if not self._file_initialized:
            ensure_dir(os.path.dirname(self.log_path))
            with open(self.log_path, "w", encoding="utf-8") as f:
                f.write("epoch,stage,metric,value\n")
            self._file_initialized = True

    @staticmethod
    def _to_float(val):
        if isinstance(val, (int, float)):
            return float(val)
        if isinstance(val, torch.Tensor):
            if val.numel() == 1:
                return float(val.detach().cpu())
        return None

    def _log_stage(self, trainer, stage: str):
        if not self._is_allowed(trainer):
            return

        prefix = f"{stage}_"
        rows = []
        for name, value in trainer.callback_metrics.items():
            if not name.startswith(prefix):
                continue
            scalar = self._to_float(value)
            if scalar is None or not math.isfinite(scalar):
                continue
            rows.append((name, scalar))

        if not rows:
            return

        self._prepare_file()
        epoch = trainer.current_epoch
        with open(self.log_path, "a", encoding="utf-8") as f:
            for name, scalar in rows:
                f.write(f"{epoch},{stage},{name},{scalar:.8f}\n")

    def on_train_epoch_end(self, trainer, pl_module):
        self._log_stage(trainer, "train")

    def on_validation_epoch_end(self, trainer, pl_module):
        self._log_stage(trainer, "val")

@torch.no_grad()
def evaluate_and_plot(
    model: PhysicallyInformedAE,
    loader: DataLoader,
    n_show: int = 3,
    *,
    outdir: str = "runs/quick_plots",
    save: bool = True,
    show: bool = False,
    dpi: int = 150,
    filename_prefix: str = "val_example",
):
    """
    Evaluates the model and (optionally) saves a few example plots.
    Returns a dict of per-parameter relative error stats.

    Arguments
    ---------
    model : PhysicallyInformedAE
    loader : DataLoader
    n_show : int            # how many figures to save/show
    outdir : str            # directory to save PNGs
    save : bool             # save PNGs to outdir
    show : bool             # call plt.show() (usually False on headless)
    dpi : int               # PNG resolution
    """
    import os
    import numpy as np
    import torch
    import matplotlib.pyplot as plt

    model.eval()
    device = model.device
    pred_names = list(getattr(model, "predict_params", []))
    if not pred_names:
        print("Aucun paramètre à évaluer."); return {}

    if save:
        os.makedirs(outdir, exist_ok=True)

    per_param_err = {p: [] for p in pred_names}
    shown = 0

    for batch in loader:
        noisy  = batch["noisy_spectra"].to(device)
        clean  = batch["clean_spectra"].to(device)
        p_norm = batch["params"].to(device)

        # provided (non-predicted) phys for inference
        provided = {}
        for name in getattr(model, "provided_params", []):
            idx = model.name_to_idx[name]
            v_phys = unnorm_param_torch(name, p_norm[:, idx])
            provided[name] = v_phys

        out   = model.infer(noisy, provided_phys=provided, refine=True, resid_target="input")
        recon = out["spectra_recon"]
        yfull = out["y_phys_full"]

        # relative errors (%)
        true_cols = [unnorm_param_torch(n, p_norm[:, model.name_to_idx[n]]) for n in pred_names]
        true_phys = torch.stack(true_cols, dim=1)
        pred_phys = torch.stack([yfull[:, model.name_to_idx[n]] for n in pred_names], dim=1)
        eps = 1e-12
        denom = torch.clamp(true_phys.abs(), min=eps)
        err_pct = 100.0 * (pred_phys - true_phys).abs() / denom
        for j, name in enumerate(pred_names):
            per_param_err[name].append(err_pct[:, j].detach().cpu())

        # quick viz
        if shown < n_show:
            i = 0
            x = np.arange(clean.shape[1])
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 4), sharex=True)
            ax1.plot(x, noisy[i].detach().cpu(),  lw=0.9, alpha=0.7, label="Noisy")
            ax1.plot(x, clean[i].detach().cpu(),  lw=1.2, label="Clean")
            ax1.plot(x, recon[i].detach().cpu(),  lw=1.0, ls="--", label="Recon")
            ax1.legend(frameon=False, fontsize=9); ax1.grid(alpha=0.25)
            ax2.plot(x, (recon[i]-noisy[i]).detach().cpu(), lw=0.9, label="Recon - Noisy")
            ax2.plot(x, (recon[i]-clean[i]).detach().cpu(), lw=0.9, label="Recon - Clean")
            ax2.axhline(0, ls=":", lw=0.7); ax2.legend(frameon=False, fontsize=9); ax2.grid(alpha=0.25)
            ax2.set_xlabel("Index spectral")
            plt.tight_layout()

            if save:
                path = os.path.join(outdir, f"{filename_prefix}_{shown}.png")
                fig.savefig(path, dpi=dpi, bbox_inches="tight")
                print(f"💾 saved {path}")
            if show:
                plt.show()
            plt.close(fig)
            shown += 1

    # aggregate stats
    stats = {}
    for name in pred_names:
        if len(per_param_err[name]) == 0:
            continue
        v = torch.cat(per_param_err[name])
        stats[name] = {
            "mean_%": float(v.mean()),
            "median_%": float(v.median()),
            "p90_%": float(torch.quantile(v, torch.tensor(0.90))),
            "p95_%": float(torch.quantile(v, torch.tensor(0.95))),
        }

    print("\n=== Erreurs relatives (%) ===")
    for k, s in stats.items():
        print(f"{k:>10s} | mean {s['mean_%']:.3f} | median {s['median_%']:.3f} | p90 {s['p90_%']:.3f} | p95 {s['p95_%']:.3f}")
    return stats


def save_error_table(stats: dict[str, dict[str, float]], path: str):
    """Enregistre un tableau CSV des erreurs relatives par paramètre."""
    if not stats:
        return
    ensure_dir(os.path.dirname(path))
    with open(path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["param", "mean_pct", "median_pct", "p90_pct", "p95_pct"])
        for name in sorted(stats.keys()):
            vals = stats[name]
            writer.writerow([
                name,
                f"{vals.get('mean_%', float('nan')):.6f}",
                f"{vals.get('median_%', float('nan')):.6f}",
                f"{vals.get('p90_%', float('nan')):.6f}",
                f"{vals.get('p95_%', float('nan')):.6f}",
            ])



# ============================================================
# 10) Helpers bornes & utils
# ============================================================
def expand_interval(a, b, factor):
    c = 0.5 * (a + b); half = 0.5 * (b - a) * float(factor)
    return float(c - half), float(c + half)

def map_ranges(base: dict, fn, per_param: dict | None = None) -> dict:
    out = {}
    for k, (a, b) in base.items():
        f = per_param.get(k, per_param.get("_default", 1.0)) if per_param else 1.0
        out[k] = fn(a, b, f)
    return out

def set_seed(seed: int):
    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); pl.seed_everything(seed, workers=True)

def ensure_dir(p: str):
    if p: os.makedirs(p, exist_ok=True)
    return p or "."

def save_json(obj: dict, path: str):
    ensure_dir(os.path.dirname(path))
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, indent=2, ensure_ascii=False)

def load_json(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

# ==== A coller dans 10_PIAE.py (près de ton objective / sampling) ====
import json
from typing import Optional, List
import optuna

def suggest_predict_list(trial: "optuna.trial.Trial") -> Optional[List[str]]:
    """
    Propose un choix pour 'predict_list' compatible avec la persistance Optuna.
    Retourne une vraie liste Python ou None.
    NOTE: on versionne le nom du param pour ne pas casser une étude existante.
    """
    def enc(x): 
        return json.dumps(x, sort_keys=True)

    choices = (
        "none",
        enc(["sig0", "dsig", "mf_CH4", "baseline1", "baseline2"]),
        enc(["sig0", "dsig", "mf_CH4"]),
        enc(["sig0", "dsig", "baseline1", "baseline2"]),
    )
    key = trial.suggest_categorical("predict_list_v2", choices)
    if key == "none":
        return None
    return json.loads(key)

# ============================================================
# 11) Construction data+modèle (config gaz & normalisation)
# ============================================================

def build_from_args(cfg: dict):
    gas = cfg.get("gas", "CH4").upper()

    # --- POLYNÔME DE FRÉQUENCE (obligatoire, inline ou chemin JSON) ---
    poly = cfg.get("poly_inline") or cfg.get("poly_freq")
    if isinstance(poly, str) and poly:
        s = poly.strip()
        if s.startswith("["):                  # JSON inline: "[a,b,c]"
            poly = json.loads(s)
        elif "," in s:                         # CSV inline: "a,b,c"
            poly = [float(x.strip()) for x in s.split(",") if x.strip()]
        else:                                  # chemin vers JSON {"poly_freq":[...]}
            poly = load_json(s)["poly_freq"]
    if not poly:
        raise ValueError("poly_inline/poly_freq requis: fournis les coefficients du polynôme de fréquence.")
    poly = list(map(float, poly))

    # --- TRANSITIONS (obligatoires, inline CSV ou chemin CSV) ---
    trans_inline = cfg.get("transitions_inline", "")
    trans_path   = cfg.get("transitions_csv", "")
    if trans_inline:
        transitions = parse_csv_transitions(trans_inline)
    elif trans_path:
        with open(trans_path, "r", encoding="utf-8") as f:
            transitions = parse_csv_transitions(f.read())
    else:
        raise ValueError("transitions_inline/transitions_csv requis: fournis les transitions (pas de défaut).")

    transitions_dict = {gas: transitions}
    device_cfg = _auto_devices()
    dev = "cuda" if device_cfg.accelerator == "gpu" else ("mps" if device_cfg.accelerator == "mps" else "cpu")
    transitions_dict = preprocess_transitions(transitions_dict, device=dev, dtype=torch.float64)



    # --------------------------
    # 2) Bornes & normalisation
    # --------------------------
    LOG_FLOOR_LOCAL = LOG_FLOOR
    default_val = {
        'sig0': (3085.43, 3085.46),
        'dsig': (0.001521, 0.00154),
        f'mf_{gas}': (max(LOG_FLOOR_LOCAL, 2e-6), max(LOG_FLOOR_LOCAL*10, 20e-6)),
        'baseline0': (0.99, 1.01),
        'baseline1': (-0.0004, -0.0003),
        'baseline2': (-4.0565E-08, -3.07117E-08),
        'P': (400, 600),
        'T': (273.15 + 30, 273.15 + 40),
    }
    expand_factors = {
        "_default": 1.0,
        'sig0': 5.0, 'dsig': 7.0, f'mf_{gas}': 2.0,
        "baseline0": 1.0, "baseline1": 3.0, "baseline2": 8.0, "P": 2.0, "T": 2.0
    }

    train_ranges = cfg.get("train_ranges")
    val_ranges   = cfg.get("val_ranges")

    # permettre fichiers/JSON inline pour ranges
    def _maybe_load_ranges(r):
        if isinstance(r, str) and r:
            s = r.strip()
            if os.path.exists(s):
                return load_json(s)
            if s[0] in "{[":
                return json.loads(s)
        return r

    train_ranges = _maybe_load_ranges(train_ranges)
    val_ranges   = _maybe_load_ranges(val_ranges)

    if not train_ranges:
        def _expand_interval(a, b, factor):
            c = 0.5 * (a + b); half = 0.5 * (b - a) * float(factor)
            return float(c - half), float(c + half)
        def _map_ranges(base: dict, fn, per_param: dict | None = None) -> dict:
            out = {}
            for k, (a, b) in base.items():
                f = per_param.get(k, per_param.get("_default", 1.0)) if per_param else 1.0
                out[k] = fn(a, b, f)
            return out
        train_ranges = _map_ranges(default_val, _expand_interval, per_param=expand_factors)
        lo, hi = train_ranges[f'mf_{gas}']
        train_ranges[f'mf_{gas}'] = (max(lo, LOG_FLOOR_LOCAL), max(hi, LOG_FLOOR_LOCAL*10))

    if not val_ranges:
        val_ranges = default_val

    # renseigne la normalisation globale
    global PARAMS, PARAM_TO_IDX, LOG_SCALE_PARAMS, NORM_PARAMS
    PARAMS = ['sig0', 'dsig', f'mf_{gas}', 'baseline0', 'baseline1', 'baseline2', 'P', 'T']
    PARAM_TO_IDX = {n: i for i, n in enumerate(PARAMS)}
    LOG_SCALE_PARAMS = {f'mf_{gas}'}
    NORM_PARAMS = train_ranges

    # --------------------------
    # 3) Jeux de données
    # --------------------------
    ds_train = SpectraDataset(
        n_samples=int(cfg.get("n_train", 1000)),
        num_points=int(cfg.get("n_points", 800)),
        gas=gas, poly_freq=poly, transitions_dict=transitions_dict,
        sample_ranges=train_ranges, with_noise=True,
        noise_profile=cfg.get("noise_train") or dict(
            std_add_range=(0, 0.08), std_mult_range=(0, 1e-2),
            p_drift=0.2, drift_sigma_range=(10.0, 120.0), drift_amp_range=(0.004, 0.05),
            p_fringes=0.2, n_fringes_range=(1, 3), fringe_freq_range=(0.05, 50.0), fringe_amp_range=(0.001, 0.015),
            p_spikes=0.2, spikes_count_range=(1, 6), spike_amp_range=(0.002, 2), spike_width_range=(1.0, 100.0),
            clip=(0.0, 1.2),
        ),
        freeze_noise=False
    )
    ds_val = SpectraDataset(
        n_samples=int(cfg.get("n_val", 2000)),
        num_points=int(cfg.get("n_points", 800)),
        gas=gas, poly_freq=poly, transitions_dict=transitions_dict,
        sample_ranges=val_ranges, with_noise=True,
        noise_profile=cfg.get("noise_val") or dict(
            std_add_range=(0, 1e-5), std_mult_range=(0, 1e-5),
            p_drift=0, drift_sigma_range=(20.0, 120.0), drift_amp_range=(0.0, 0.01),
            p_fringes=0, n_fringes_range=(1, 2), fringe_freq_range=(0.5, 10.0), fringe_amp_range=(0.0, 0.004),
            p_spikes=0.0, spikes_count_range=(1, 2), spike_amp_range=(0.0, 0.01), spike_width_range=(1.0, 3.0),
            clip=(0.0, 1.2),
        ),
        freeze_noise=True
    )

    # --------------------------
    # 4) DataLoaders
    # --------------------------

    env_workers = os.environ.get("PHYS_NUM_WORKERS") or cfg.get("num_workers")
    if env_workers is not None:
        try:
            num_workers = max(0, int(env_workers))
        except (TypeError, ValueError):
            raise ValueError(f"num_workers invalide: {env_workers}")
    else:
        cpu_total = max(1, os.cpu_count() or 1)
        denom = max(1, device_cfg.world_size)
        num_workers = max(1, min(8, cpu_total // denom)) if cpu_total > 1 else 0
    pin_memory = device_cfg.accelerator == "gpu"
    common = dict(
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=(num_workers > 0),
        collate_fn=collate_fn,
    )
    if num_workers > 0:
        pf = cfg.get("prefetch_factor", 2)
        try:
            pf_int = max(1, int(pf))
        except (TypeError, ValueError):
            raise ValueError(f"prefetch_factor invalide: {pf}")
        common["prefetch_factor"] = pf_int
    train_loader = DataLoader(ds_train, batch_size=int(cfg.get("batch_size", 32)), shuffle=True, drop_last=True, **common)
    val_loader   = DataLoader(ds_val,   batch_size=int(cfg.get("batch_size", 32)), shuffle=False, drop_last=False, **common)


    # --------------------------
    # 5) Modèle
    # --------------------------
    predict_list = cfg.get("predict_list") or ['sig0', 'dsig', f'mf_{gas}', 'baseline1', 'baseline2']
    film_list    = cfg.get("film_list")    or ['P', 'T']

    model = PhysicallyInformedAE(
        gas=gas, n_points=int(cfg.get("n_points", 800)), param_names=PARAMS,
        poly_freq_CH4=poly, transitions_dict=transitions_dict,
        lr=float(cfg.get("base_lr", 1e-4)),
        alpha_param=float(cfg.get("alpha_param", 0.3)),
        alpha_phys=float(cfg.get("alpha_phys", 0.7)),
        head_mode="multi", predict_params=predict_list, film_params=film_list,
        refine_steps=int(cfg.get("refine_steps", 0)),
        refine_delta_scale=float(cfg.get("refine_delta_scale", 0.1)),
        refine_target=str(cfg.get("refine_target", "noisy")),
        refine_warmup_epochs=int(cfg.get("refine_warmup_epochs", 30)),
        freeze_base_epochs=int(cfg.get("freeze_base_epochs", 20)),
        base_lr=float(cfg.get("base_lr", 1e-4)),
        refiner_lr=float(cfg.get("refiner_lr", 1e-5)),
        recon_max1=True,
        corr_mode=str(cfg.get("corr_mode", "none")),
        corr_savgol_win=int(cfg.get("sg_win", 15)),
        corr_savgol_poly=int(cfg.get("sg_poly", 3)),
        weight_mf=float(cfg.get("weight_mf", 1.0)),
        # EfficientNet scaling
        width_mult=float(cfg.get("width_mult", 1.0)),
        depth_mult=float(cfg.get("depth_mult", 1.0)),
        ref_width_mult=(float(cfg["ref_width_mult"]) if cfg.get("ref_width_mult") is not None else None),
        ref_depth_mult=(float(cfg["ref_depth_mult"]) if cfg.get("ref_depth_mult") is not None else None),
        se_ratio=float(cfg.get("se_ratio", 0.25)),
        group_norm_groups=int(cfg.get("group_norm_groups", 8)),
        # HP de tête
        head_hidden_mult=float(cfg.get("head_hidden_mult", 0.5)),
        head_hidden_min=int(cfg.get("head_hidden_min", 128)),
        head_layers=int(cfg.get("head_layers", 2)),
        head_dropout=float(cfg.get("head_dropout", 0.0)),
        head_activation=str(cfg.get("head_activation", "gelu")),
        head_norm=str(cfg.get("head_norm", "layer")),
    )

        # exposer les profils de bruit au module
    model.train_noise_profile = dict(ds_train.noise_profile)
    model.val_noise_profile   = dict(ds_val.noise_profile)
    model.with_noise_train    = bool(ds_train.with_noise)
    model.with_noise_val      = bool(ds_val.with_noise)


    # -- appliquer un override de stage (A/B1/B2) si demandé dans cfg
    if cfg.get("stage_override"):
        st = str(cfg["stage_override"]).upper()
        if st == "B":   # compat arrière
            st = "B1"
        model.set_stage_mode(st)

    return model, train_loader, val_loader

# ---------------------------
# CSV logger & early stop Optuna (identiques à ton 2e script)
# ---------------------------
class CSVLoggerCallback:
    HEADER = [
        "trial",
        "base_lr","refiner_lr","batch_size","width_mult","depth_mult",
        "se_ratio","group_norm_groups","alpha_phys","alpha_param",
        "refine_steps","refine_delta_scale","corr_mode","sg_win","sg_poly",
        "film","predict_list",
        "head_hidden_mult","head_hidden_min","head_layers","head_dropout","head_activation","head_norm",
        "val_loss","val_phys","val_corr","val_params"
    ]

    def __init__(self, csv_file="optuna_results.csv", force_header_if_empty=True):
        self.csv_file = csv_file
        self._wrote_header = False
        if force_header_if_empty:
            # Écrit l'entête si fichier absent ou vide
            need_header = (not os.path.exists(self.csv_file)) or (os.path.getsize(self.csv_file) == 0)
            if need_header:
                os.makedirs(os.path.dirname(self.csv_file) or ".", exist_ok=True)
                with open(self.csv_file, "w", newline="") as f:
                    writer = csv.writer(f)
                    writer.writerow(self.HEADER)
                self._wrote_header = True

    def __call__(self, study, trial):
        # Sécurité: si quelqu’un a effacé le fichier entre-temps, on remet l'entête
        if (not os.path.exists(self.csv_file)) or (os.path.getsize(self.csv_file) == 0):
            with open(self.csv_file, "w", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(self.HEADER)
            self._wrote_header = True

        p = trial.params
        with open(self.csv_file, "a", newline="") as f:
            writer = csv.writer(f)
            writer.writerow([
                trial.number,
                p.get("base_lr"), p.get("refiner_lr"), p.get("batch_size"),
                p.get("width_mult"), p.get("depth_mult"),
                p.get("se_ratio"), p.get("group_norm_groups"),
                p.get("alpha_phys"), p.get("alpha_param"),
                p.get("refine_steps"), p.get("refine_delta_scale"),
                p.get("corr_mode"), p.get("sg_win"), p.get("sg_poly"),
                p.get("film"), json.dumps(p.get("predict_list")),
                p.get("head_hidden_mult"), p.get("head_hidden_min"),
                p.get("head_layers"), p.get("head_dropout"),
                p.get("head_activation"), p.get("head_norm"),
                trial.user_attrs.get("val_loss"),
                trial.user_attrs.get("val_phys"),
                trial.user_attrs.get("val_corr"),
                trial.user_attrs.get("val_params"),
            ])


class StopAfterNTrials:
    def __init__(self, max_trials): self.max_trials = max_trials
    def __call__(self, study: optuna.Study, trial: optuna.trial.FrozenTrial):
        done = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
        if len(done) >= self.max_trials:
            print(f"> Arrêt forcé après {self.max_trials} trials complétés.")
            study.stop()

# ---------------------------
# Utilitaires
# ---------------------------
def _odd(x: int) -> int:
    return x if x % 2 == 1 else (x + 1)

def _env_int(*keys: str) -> Optional[int]:
    for key in keys:
        raw = os.environ.get(key)
        if raw is None or raw == "":
            continue
        try:
            return int(raw)
        except ValueError:
            cleaned = raw.replace(" ", "")
            if "," in cleaned:
                for part in cleaned.split(","):
                    if part.isdigit():
                        return int(part)
            if "(" in cleaned:
                prefix = cleaned.split("(", 1)[0]
                if prefix.isdigit():
                    return int(prefix)
    return None


def _count_visible_cuda_devices() -> int:
    spec = os.environ.get("CUDA_VISIBLE_DEVICES")
    if spec is None or spec.strip() == "":
        return torch.cuda.device_count()
    tokens = [t.strip() for t in spec.split(",") if t.strip() not in {"", "-1"}]
    return len(tokens)


def _auto_devices() -> TrainerDeviceConfig:
    if torch.cuda.is_available():
        accelerator = "gpu"
        precision = "32-true" if torch.cuda.get_device_capability(0)[0] >= 8 else "32"
        local_default = max(1, _count_visible_cuda_devices())
        requested_local = _env_int("LOCAL_WORLD_SIZE", "SLURM_GPUS_ON_NODE", "MPI_LOCALNRANKS")
        devices_per_node = max(1, min(local_default, requested_local or local_default))
    elif torch.backends.mps.is_available():
        accelerator = "mps"
        precision = "32"
        local_default = 1
        devices_per_node = 1
    else:
        accelerator = "cpu"
        precision = "32"
        cpu_total = max(1, os.cpu_count() or 1)
        requested_local = _env_int("LOCAL_WORLD_SIZE", "SLURM_TASKS_PER_NODE", "OMP_NUM_THREADS")
        if requested_local is None or requested_local <= 0:
            requested_local = min(cpu_total, max(1, cpu_total // 2))
        devices_per_node = max(1, min(cpu_total, requested_local))

    world_env = _env_int("WORLD_SIZE", "SLURM_NTASKS", "PMI_SIZE", "OMPI_COMM_WORLD_SIZE")
    nodes_env = _env_int("SLURM_NNODES", "SLURM_JOB_NUM_NODES", "NNODES", "OMPI_COMM_WORLD_NUM_NODES")
    num_nodes = max(1, nodes_env or 1)

    if world_env and world_env > 0:
        if nodes_env:
            num_nodes = max(1, nodes_env)
            per_node = max(1, math.ceil(world_env / num_nodes))
            devices_per_node = max(1, min(devices_per_node, per_node))
        else:
            num_nodes = max(1, math.ceil(world_env / devices_per_node))
        total_slots = max(1, devices_per_node * num_nodes)
        if total_slots > world_env:
            per_node = max(1, math.ceil(world_env / num_nodes))
            devices_per_node = max(1, min(devices_per_node, per_node))
        if accelerator == "gpu":
            devices_per_node = max(1, min(devices_per_node, _count_visible_cuda_devices()))
        else:
            if accelerator == "cpu":
                devices_per_node = max(1, min(devices_per_node, os.cpu_count() or devices_per_node))

    strategy_env = os.environ.get("PL_TRAINER_STRATEGY") or os.environ.get("PHYS_TRAINER_STRATEGY")
    use_ddp = (devices_per_node > 1) or (num_nodes > 1)
    strategy = strategy_env or ("ddp" if use_ddp else None)

    return TrainerDeviceConfig(
        accelerator=accelerator,
        devices=int(devices_per_node),
        precision=precision,
        num_nodes=int(num_nodes),
        strategy=strategy,
    )



def set_all_seeds(seed: int = 42):
    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); pl.seed_everything(seed, workers=True)

class OptunaPruneCallback(pl.Callback):
    def __init__(self, trial, monitor: str = "val_loss"):
        super().__init__()
        self.trial = trial
        self.monitor = monitor

    def on_validation_end(self, trainer, pl_module):
        metric = trainer.callback_metrics.get(self.monitor)
        if metric is None:
            return
        self.trial.report(float(metric), step=trainer.current_epoch)
        if self.trial.should_prune():
            # Optionnel: limiter au rank 0 si DDP
            if getattr(trainer, "is_global_zero", True):
                raise optuna.exceptions.TrialPruned()
            
# ===== Optuna viz — version robuste (Axes vs Figure, polices HPC, filtres) =====
# ===== Optuna viz — suppression des warnings & layout robuste =====
import os, json, warnings, matplotlib as mpl
from matplotlib.figure import Figure
from matplotlib.axes import Axes

def _to_figure(obj):
    import numpy as np
    import matplotlib.pyplot as plt
    if hasattr(obj, "figure"):          # Axes
        return obj.figure
    if hasattr(obj, "get_figure"):      # Axes
        return obj.get_figure()
    if hasattr(obj, "savefig"):         # Figure
        return obj
    if isinstance(obj, (list, tuple)):
        return _to_figure(obj[0])
    if isinstance(obj, np.ndarray):
        return _to_figure(obj.flat[0])
    raise TypeError(f"Objet non pris en charge pour savefig: {type(obj)}")

def _save_fig(obj, path, dpi=150):
    import matplotlib.pyplot as plt  
    fig = _to_figure(obj)
    fig.canvas.draw()
    fig.savefig(path, dpi=dpi, bbox_inches="tight")
    plt.close(fig)

def save_optuna_figures(study: "optuna.Study", outdir: str, *, save_html: bool = False, dpi: int = 150):
    """
    Crée des PNG (et HTML optionnels) des visualisations Optuna…
    …en ignorant les hyperparams constants (évite 'unique value length < 2').
    """
    from optuna.visualization.matplotlib import (
        plot_optimization_history, plot_intermediate_values, plot_slice,
        plot_param_importances, plot_parallel_coordinate, plot_contour, plot_edf
    )
    os.makedirs(outdir, exist_ok=True)

    complete = [t for t in study.trials if t.state.name == "COMPLETE"]
    varied_params = set()
    if complete:
        all_params = {k for t in complete for k in t.params.keys()}
        for p in sorted(all_params):
            vals = [t.params.get(p) for t in complete if p in t.params]
            if len(set(vals)) >= 2:
                varied_params.add(p)
    varied_list = sorted(varied_params)

    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning, module=r"optuna(\.visualization(\.matplotlib)?)?")
        warnings.filterwarnings("ignore", message=r"Param .* unique value length is less than 2")
        warnings.filterwarnings("ignore", message=r"Output figures of this Matplotlib-based .*plot_contour.*")
        warnings.filterwarnings("ignore", message=r"Tight layout not applied.*")
        with mpl.rc_context({"font.family": ["DejaVu Sans", "sans-serif"], "axes.unicode_minus": False}):
            figs = []
            try: figs.append(("optimization_history.png",  plot_optimization_history(study)))
            except Exception as e: print(f"[viz] optimization_history: {e}")
            try: figs.append(("intermediate_values.png",  plot_intermediate_values(study)))
            except Exception as e: print(f"[viz] intermediate_values: {e}")
            if varied_list:
                try: figs.append(("slice.png",             plot_slice(study, params=varied_list)))
                except Exception as e: print(f"[viz] slice: {e}")
                try: figs.append(("param_importances.png", plot_param_importances(study, params=varied_list)))
                except Exception as e: print(f"[viz] param_importances: {e}")
                if len(varied_list) >= 2:
                    try: figs.append(("parallel_coordinate.png", plot_parallel_coordinate(study, params=varied_list)))
                    except Exception as e: print(f"[viz] parallel_coordinate: {e}")
                    try: figs.append(("contour.png", plot_contour(study, params=varied_list)))
                    except Exception as e: print(f"[viz] contour: {e}")
            try: figs.append(("edf.png", plot_edf(study)))
            except Exception as e: print(f"[viz] edf: {e}")
            for fname, obj in figs:
                try: _save_fig(obj, os.path.join(outdir, fname), dpi=dpi)
                except Exception as e: print(f"[viz] save {fname}: {e}")

    # Résumé JSON
    try:
        best = study.best_trial
        summary = {
            "best_trial": best.number,
            "best_value": study.best_value,
            "n_trials": len(study.trials),
            "params": best.params,
            "user_attrs": {k: best.user_attrs.get(k) for k in ("val_loss","val_phys","val_corr","val_params")},
        }
        with open(os.path.join(outdir, "summary.json"), "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"[viz] summary.json: {e}")

    # HTML (Plotly) optionnel
    if save_html:
        try:
            import optuna.visualization as vz
            charts = {
                "optimization_history.html": vz.plot_optimization_history(study),
                "intermediate_values.html":  vz.plot_intermediate_values(study),
                "edf.html":                  vz.plot_edf(study),
            }
            if varied_list:
                charts["slice.html"] = vz.plot_slice(study, params=varied_list)
                charts["param_importances.html"] = vz.plot_param_importances(study, params=varied_list)
                if len(varied_list) >= 2:
                    charts["parallel_coordinate.html"] = vz.plot_parallel_coordinate(study, params=varied_list)
                    charts["contour.html"] = vz.plot_contour(study, params=varied_list)
            for fname, fig in charts.items():
                if fig is not None:
                    fig.write_html(os.path.join(outdir, fname), include_plotlyjs="cdn")
        except Exception as e:
            print(f"[viz] HTML ignoré: {e}")

def finalize_optuna_run(
    study: "optuna.Study",
    study_dir: str,
    *,
    figdir: str | None = None,
    save_html: bool = False,
    viz_dpi: int = 150,
    topk: int = 15,
):
    """
    Post-traitement d'une étude Optuna:
      - écrit best.json + topK.csv
      - exporte des figures Matplotlib (et HTML optionnel)
    """
    os.makedirs(study_dir, exist_ok=True)
    figdir = figdir or os.path.join(study_dir, "figs")
    os.makedirs(figdir, exist_ok=True)

    # 1) Fichiers récap
    try:
        best = study.best_trial
        best_payload = {
            "best_trial": best.number,
            "best_value": study.best_value,
            "params": best.params,
            "user_attrs": {
                "val_loss": best.user_attrs.get("val_loss"),
                "val_phys": best.user_attrs.get("val_phys"),
                "val_corr": best.user_attrs.get("val_corr"),
                "val_params": best.user_attrs.get("val_params"),
                "refine_target": best.user_attrs.get("refine_target"),
                "predict_list": best.user_attrs.get("predict_list"),
                "film": best.user_attrs.get("film"),
            },
            "state": best.state.name,
        }
        with open(os.path.join(study_dir, "best.json"), "w", encoding="utf-8") as f:
            json.dump(best_payload, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"[finalize] best.json: {e}")

    # 2) Top-K CSV
    try:
        import csv
        complete = [t for t in study.trials if t.state.name == "COMPLETE"]
        complete.sort(key=lambda t: t.value)
        rows = []
        for t in complete[:topk]:
            rows.append({
                "trial": t.number,
                "value": t.value,
                **{f"p:{k}": v for k, v in t.params.items()},
                **{f"ua:{k}": t.user_attrs.get(k) for k in ("val_loss","val_phys","val_corr","val_params")},
            })
        csv_path = os.path.join(study_dir, f"top{topk}.csv")
        if rows:
            keys = sorted({k for r in rows for k in r.keys()}, key=lambda x: (not x.startswith("p:"), x))
            with open(csv_path, "w", newline="") as f:
                w = csv.DictWriter(f, fieldnames=keys)
                w.writeheader()
                for r in rows:
                    w.writerow(r)
        else:
            # au moins créer un CSV vide avec header minimal
            with open(csv_path, "w", newline="") as f:
                w = csv.writer(f); w.writerow(["trial","value"])
    except Exception as e:
        print(f"[finalize] topK.csv: {e}")

    # 3) Figures
    try:
        save_optuna_figures(study, figdir, save_html=save_html, dpi=viz_dpi)
    except Exception as e:
        print(f"[finalize] figures: {e}")

    print(f"[finalize] OK → study_dir={study_dir}  |  figs={figdir}")

# ---------------------------
# OBJECTIVE OPTUNA
# ---------------------------
def make_objective(args):
    # Charge la config de base (fichier ou JSON inline)
    if args.cfg and os.path.exists(args.cfg):
        base_cfg = json.load(open(args.cfg, "r", encoding="utf-8"))
    elif args.cfg and args.cfg.strip().startswith("{"):
        base_cfg = json.loads(args.cfg)
    else:
        raise RuntimeError("--cfg requis (chemin fichier JSON ou JSON inline).")

    GAS = base_cfg.get("gas", "CH4").upper()
    MF_KEY = f"mf_{GAS}"

    def objective(trial: optuna.trial.Trial) -> float:
        # ===== (1) Choix “de base” =====
        batch_size = trial.suggest_categorical("batch_size", [16, 24, 32, 48, 64])

        # Archi backbone
        width_mult = trial.suggest_float("width_mult", 0.75, 1.9)
        depth_mult = trial.suggest_float("depth_mult", 0.6, 1.6)
        group_norm_groups = trial.suggest_categorical("group_norm_groups", [8, 16, 32])
        se_ratio = trial.suggest_float("se_ratio", 0.10, 0.45)

        # Raffineur
        refine_steps = trial.suggest_int("refine_steps", 0, 2)
        if refine_steps > 0:
            ref_width_mult     = trial.suggest_float("ref_width_mult", 0.75, 1.9)
            ref_depth_mult     = trial.suggest_float("ref_depth_mult", 0.6, 1.6)
            refine_delta_scale = trial.suggest_float("refine_delta_scale", 0.05, 0.30)
        else:
            ref_width_mult = None
            ref_depth_mult = None
            refine_delta_scale = 0.1

        # ===== (1b) Valeurs FIXES (pas optimisées) lues depuis la cfg =====
        refine_target = base_cfg.get("refine_target", "noisy")
        predict_list = get_predict_list_A(base_cfg)

        # FiLM (pris depuis la cfg pour rester déterministe vis-à-vis d'Optuna)
        film = bool(base_cfg.get("film", False))

        # Optim
        base_lr    = trial.suggest_float("base_lr", 1e-5, 5e-4, log=True)
        refiner_lr = trial.suggest_float("refiner_lr", 5e-7, 2e-4, log=True)

        # Pertes
        alpha_phys  = trial.suggest_float("alpha_phys", 0.3, 1.5)
        alpha_param = trial.suggest_float("alpha_param", 0.0, 1.0)

        predicts_mf = (predict_list is None) or (MF_KEY in (predict_list or []))
        weight_mf = trial.suggest_float("weight_mf", 0.5, 5.0, log=True) if predicts_mf else 1.0

        # Staging/warmup
        refine_warmup_epochs = trial.suggest_int("refine_warmup_epochs", 10, 60)
        freeze_base_epochs   = trial.suggest_int(
            "freeze_base_epochs",
            refine_warmup_epochs + 5,
            max(refine_warmup_epochs + 5, 80)
        )

        # Corr / dérivées
        corr_mode = trial.suggest_categorical("corr_mode", ["savgol"])
        if corr_mode == "savgol":
            sg_win  = _odd(trial.suggest_int("sg_win", 7, 61))
            sg_poly = trial.suggest_int("sg_poly", 2, 5)
        else:
            sg_win, sg_poly = 15, 3  # (ne devrait pas arriver ici)

        # ===== (2) TÊTE MLP =====
        head_hidden_mult = trial.suggest_float("head_hidden_mult", 0.35, 1.5)
        head_hidden_min  = trial.suggest_categorical("head_hidden_min", [64, 96, 128, 160, 192, 256])
        head_layers      = trial.suggest_int("head_layers", 1, 4)
        head_dropout     = trial.suggest_float("head_dropout", 0.0, 0.35)
        head_activation  = trial.suggest_categorical("head_activation", ["gelu", "silu", "relu", "tanh"])
        head_norm        = trial.suggest_categorical("head_norm", ["layer", "batch", "none"])

        # ===== (3) Composer la cfg pour build =====
        cfg = dict(base_cfg)
        cfg.update({
            "batch_size": batch_size,
            "width_mult": width_mult, "depth_mult": depth_mult,
            "group_norm_groups": group_norm_groups,
            "se_ratio": se_ratio, 
            "base_lr": base_lr, "refiner_lr": refiner_lr,
            "alpha_phys": alpha_phys, "alpha_param": alpha_param,
            "weight_mf": weight_mf,
            "predict_list": predict_list,          # fixé depuis la cfg (et/ou ALL_TARGETS)
            "refine_steps": refine_steps, "refine_delta_scale": refine_delta_scale,
            "refine_target": refine_target,        # fixé depuis la cfg
            "refine_warmup_epochs": refine_warmup_epochs, "freeze_base_epochs": freeze_base_epochs,
            "corr_mode": corr_mode, "sg_win": sg_win, "sg_poly": sg_poly,
            "head_hidden_mult": head_hidden_mult,
            "head_hidden_min": head_hidden_min,
            "head_layers": head_layers,
            "head_dropout": head_dropout,
            "head_activation": head_activation,
            "head_norm": head_norm,
        })
        if refine_steps > 0:
            cfg["ref_width_mult"] = ref_width_mult
            cfg["ref_depth_mult"] = ref_depth_mult
        else:
            cfg["ref_width_mult"] = None
            cfg["ref_depth_mult"] = None

        # Active/désactive FiLM via la liste de conditions
        cfg["film_list"] = (base_cfg.get("film_list") or ['P', 'T']) if film else []

        # (optionnel) tracer les valeurs fixes dans l'étude
        trial.set_user_attr("refine_target", refine_target)
        trial.set_user_attr("predict_list", json.dumps(predict_list))
        trial.set_user_attr("film", film)

        trial_root = getattr(
            args,
            "_trials_root",
            os.path.join(args.io_root or "optuna_runs", args.study_name, "trials")
        )
        trial_dir = os.path.join(trial_root, f"trial_{trial.number:04d}")
        ensure_dir(trial_dir)
        save_json(cfg, os.path.join(trial_dir, "cfg_used.json"))
        save_json({"trial": trial.number, "params": dict(trial.params)}, os.path.join(trial_dir, "trial_params.json"))
        trial.set_user_attr("artifact_dir", trial_dir)
        metrics_logger = EpochMetricsLogger(os.path.join(trial_dir, "metrics.out"))

        # ===== (4) Build + court entraînement =====
        set_all_seeds(1337 + trial.number)
        model, train_loader, val_loader = build_from_args(cfg)
        model.set_film_usage(len(cfg.get("film_list", [])) > 0)

        device_cfg = _auto_devices()

        prune_cb = OptunaPruneCallback(trial, monitor="val_loss")

        trainer = pl.Trainer(
            max_epochs=args.max_epochs,
            **device_cfg.to_trainer_kwargs(),
            logger=False, enable_progress_bar=False, enable_checkpointing=False,
            default_root_dir=trial_dir,
            callbacks=[UpdateEpochInDataset(), metrics_logger, prune_cb],
        )
        try:
            trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)
        except optuna.exceptions.TrialPruned:
            raise
        else:
            if _is_master() and val_loader is not None:
                figs_dir = os.path.join(trial_dir, "figures")
                stats = evaluate_and_plot(
                    model,
                    val_loader,
                    n_show=1,
                    outdir=figs_dir,
                    save=True,
                    show=False,
                    dpi=200,
                    filename_prefix=f"trial{trial.number:04d}",
                )
                save_error_table(stats, os.path.join(trial_dir, "val_errors.csv"))
                save_json(stats, os.path.join(trial_dir, "val_errors.json"))

        val_loss   = trainer.callback_metrics.get("val_loss")
        val_phys   = trainer.callback_metrics.get("val_phys")
        val_corr   = trainer.callback_metrics.get("val_corr")
        val_params = trainer.callback_metrics.get("val_params")
        if val_loss is None:
            raise RuntimeError("val_loss introuvable dans callback_metrics.")

        trial.set_user_attr("val_loss", float(val_loss))
        if val_phys is not None:   trial.set_user_attr("val_phys", float(val_phys))
        if val_corr is not None:   trial.set_user_attr("val_corr", float(val_corr))
        if val_params is not None: trial.set_user_attr("val_params", float(val_params))
        return float(val_loss)

    return objective

def _is_master():
    import os
    # Rang "0" pour torch/SLURM; fallback=maître si non défini
    for k in ("SLURM_PROCID", "RANK", "LOCAL_RANK"):
        v = os.environ.get(k)
        if v is not None:
            try:
                return int(v) == 0
            except Exception:
                pass
    return True

# ---------------------------
# MAIN (run | optuna)
# ---------------------------
def main():
    parser = argparse.ArgumentParser(description="Entraînement ou HPO Optuna pour PhysicallyInformedAE")
    parser.add_argument("mode", choices=["run","optuna"], help="run = entraînement classique, optuna = HPO")
    parser.add_argument("--cfg", type=str, required=True,
                        help="Chemin vers un JSON (ou JSON inline) pour build_from_args (poly/transitions/ranges).")
    parser.add_argument("--max-epochs", type=int, default=100)

    # options mode run (hyperparamètres fixes, écrasent le cfg)
    parser.add_argument("--batch-size", type=int, default=None)
    parser.add_argument("--width-mult", type=float, default=None)
    parser.add_argument("--depth-mult", type=float, default=None)
    parser.add_argument("--se-ratio", type=float, default=None)
    parser.add_argument("--base-lr", type=float, default=None)
    parser.add_argument("--refiner-lr", type=float, default=None)
    parser.add_argument("--alpha-phys", type=float, default=None)
    parser.add_argument("--alpha-param", type=float, default=None)
    parser.add_argument("--refine-steps", type=int, default=None)
    parser.add_argument("--refine-delta-scale", type=float, default=None)
    parser.add_argument("--corr-mode", choices=["none","central","savgol"], default=None)
    parser.add_argument("--sg-win", type=int, default=None)
    parser.add_argument("--sg-poly", type=int, default=None)
    parser.add_argument("--film", action="store_true", help="Active FiLM (utilise film_list du cfg ou ['P','T']).")
    parser.add_argument("--no-film", action="store_true", help="Désactive FiLM.")

    # nouveaux flags: stage & I/O des blocs
    parser.add_argument("--stage-override", choices=["A","B","B1","B2"], default=None,
                        help="Force le stage: A=backbone+heads only, B/B1=refiner only (A gelé), B2=finetune conjoint.")
    parser.add_argument("--load-a", type=str, default=None, help="Chemin A_only.pth à charger avant entraînement.")
    parser.add_argument("--load-refiner", type=str, default=None, help="Chemin refiner_only_*.pth à charger avant entraînement.")
    parser.add_argument("--export-a", type=str, default=None, help="Chemin pour exporter A_only après l'entraînement.")
    parser.add_argument("--export-refiner", type=str, default=None, help="Chemin pour exporter Refiner_only après l'entraînement.")
    parser.add_argument("--io-root", type=str, default=None,
                        help="Répertoire racine où stocker les entrées/sorties générées (cfg, métriques, figures).")

    # options Optuna
    parser.add_argument("--n-trials", type=int, default=50)
    parser.add_argument("--study-name", type=str, default="PIAE_HPO")
    parser.add_argument("--storage", type=str, default=None,
                        help="Ex: 'journal:optuna_runs/PIAE/optuna_journal.log'. Si None, créé auto.")
    parser.add_argument("--csv", type=str, default=None,
                        help="Chemin CSV résultats. Si None, créé auto à côté du journal.")
    args = parser.parse_args()

    if args.mode == "run":
        # charge & écrase le cfg
        cfg = json.load(open(args.cfg, "r", encoding="utf-8")) if os.path.exists(args.cfg) else json.loads(args.cfg)

        def _maybe_set(key, val):
            if val is not None:
                cfg[key] = val

        _maybe_set("batch_size", args.batch_size)
        _maybe_set("width_mult", args.width_mult)
        _maybe_set("depth_mult", args.depth_mult)
        _maybe_set("se_ratio", args.se_ratio)
        _maybe_set("base_lr", args.base_lr)
        _maybe_set("refiner_lr", args.refiner_lr)
        _maybe_set("alpha_phys", args.alpha_phys)
        _maybe_set("alpha_param", args.alpha_param)
        _maybe_set("refine_steps", args.refine_steps)
        _maybe_set("refine_delta_scale", args.refine_delta_scale)
        _maybe_set("corr_mode", args.corr_mode)
        if args.sg_win is not None:
            cfg["sg_win"] = _odd(args.sg_win)
        if args.sg_poly is not None:
            cfg["sg_poly"] = int(args.sg_poly)

        # FiLM on/off depuis la CLI
        if args.film and not args.no_film:
            cfg["film_list"] = cfg.get("film_list") or ['P', 'T']
        if args.no_film:
            cfg["film_list"] = []

        # stage override (A/B/B1/B2) si demandé → mis en cfg et appliqué dans build_from_args()
        if args.stage_override is not None:
            st = args.stage_override.upper()
            if st == "B":  # compat
                st = "B1"
            cfg["stage_override"] = st

        run_root = ensure_dir(args.io_root or os.path.join("runs", "single_run"))
        save_json(cfg, os.path.join(run_root, "cfg_used.json"))
        if args.cfg and not args.cfg.strip().startswith("{") and os.path.exists(args.cfg):
            try:
                # copie du fichier de config d'origine pour traçabilité
                import shutil
                shutil.copy2(args.cfg, os.path.join(run_root, "cfg_source.json"))
            except Exception as e:
                print(f"[warn] Impossible de copier la cfg source: {e}")

        set_all_seeds(42)
        model, train_loader, val_loader = build_from_args(cfg)
        model.set_film_usage(len(cfg.get("film_list", [])) > 0)

        # chargements optionnels des blocs (avant entraînement)
        if args.load_a:
            print(f"↪️  Chargement A_only depuis {args.load_a}")
            load_block_A_only(model, args.load_a, strict=False)
        if args.load_refiner:
            print(f"↪️  Chargement Refiner_only depuis {args.load_refiner}")
            load_block_refiner_only(model, args.load_refiner, strict=False)

        device_cfg = _auto_devices()
        metrics_logger = EpochMetricsLogger(os.path.join(run_root, "metrics.out"))

        trainer = pl.Trainer(
            max_epochs=args.max_epochs,
            **device_cfg.to_trainer_kwargs(),
            default_root_dir=run_root,
            callbacks=[UpdateEpochInDataset(), metrics_logger],
        )
        trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)

        print("✅ Fin d'entraînement. Dernier val_loss:",
              float(trainer.callback_metrics.get("val_loss", float("nan"))))

        if _is_master() and val_loader is not None:
            figs_dir = os.path.join(run_root, "figures")
            stats = evaluate_and_plot(
                model,
                val_loader,
                n_show=1,
                outdir=figs_dir,
                save=True,
                show=False,
                dpi=200,
                filename_prefix="run",
            )
            save_error_table(stats, os.path.join(run_root, "val_errors.csv"))
            save_json(stats, os.path.join(run_root, "val_errors.json"))
            print(f"📊 Statistiques validation enregistrées dans {run_root}")

        # exports optionnels après entraînement
        if args.export_a:
            save_block_A_only(model, args.export_a)
            print(f"💾 A_only sauvegardé → {args.export_a}")
        if args.export_refiner:
            save_block_refiner_only(model, args.export_refiner)
            print(f"💾 Refiner_only sauvegardé → {args.export_refiner}")
        return

    # ---- Mode OPTUNA ----
    root = args.io_root or "optuna_runs"
    os.makedirs(root, exist_ok=True)
    study_dir = os.path.join(root, args.study_name)
    os.makedirs(study_dir, exist_ok=True)
    trials_root = os.path.join(study_dir, "trials")
    os.makedirs(trials_root, exist_ok=True)
    args._study_dir = study_dir
    args._trials_root = trials_root
    journal_path = args.storage.split("journal:")[1] if (args.storage and args.storage.startswith("journal:")) \
                   else os.path.join(study_dir, "optuna_journal.log")
    csv_path = args.csv or os.path.join(study_dir, "optuna_results.csv")

    storage = JournalStorage(JournalFileBackend(journal_path))
    study = optuna.create_study(
        study_name=args.study_name,
        storage=storage,
        direction="minimize",
        load_if_exists=True,
        sampler=optuna.samplers.TPESampler(multivariate=True, group=True),
        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=0)
    )

    csv_cb = CSVLoggerCallback(csv_path)
    stop_cb = StopAfterNTrials(args.n_trials)

    objective = make_objective(args)
    study.optimize(objective, n_trials=args.n_trials, callbacks=[csv_cb, stop_cb])
    # après study.optimize(...)
    if _is_master():
        finalize_optuna_run(
            study, study_dir,
            figdir=os.path.join(study_dir, "figs"),
            save_html=bool(getattr(args, "html", False)),
            viz_dpi=150
        )

    print(f"🥇 Best trial #{study.best_trial.number} → val_loss={study.best_value:.6f}")
    print(f"📂 Journal: {journal_path}")
    print(f"📄 CSV:     {csv_path}")

# ============================================================
# 10.b) I/O poids: A_only et Refiner_only
# ============================================================
def extract_state_dict_A_only(model: "PhysicallyInformedAE") -> dict:
    sd = {}
    sd["backbone"] = model.backbone.state_dict()
    sd["shared_head"] = model.shared_head.state_dict()
    if hasattr(model, "out_head") and model.out_head is not None:
        sd["out_head"] = model.out_head.state_dict()
    if hasattr(model, "out_heads") and model.out_heads is not None:
        sd["out_heads"] = {k: v.state_dict() for k, v in model.out_heads.items()}
    if getattr(model, "film", None) is not None:
        sd["film"] = model.film.state_dict()
        # film_mask est un buffer -> sauvé pour cohérence
        sd["film_mask"] = getattr(model, "film_mask", None)
    sd["_meta"] = {
        "param_names": getattr(model, "param_names", None),
        "predict_params": getattr(model, "predict_params", None),
        "film_params": getattr(model, "film_params", None),
        "feat_dim": int(model.backbone.feat_dim),
    }
    return sd

def load_block_A_only(model: "PhysicallyInformedAE", path: str, strict: bool = False):
    pkg = torch.load(path, map_location="cpu")
    if "backbone" in pkg: model.backbone.load_state_dict(pkg["backbone"], strict=strict)
    if "shared_head" in pkg: model.shared_head.load_state_dict(pkg["shared_head"], strict=strict)
    if "out_head" in pkg and hasattr(model, "out_head"):
        model.out_head.load_state_dict(pkg["out_head"], strict=strict)
    if "out_heads" in pkg and hasattr(model, "out_heads"):
        for k, sd in pkg["out_heads"].items():
            if k in model.out_heads:
                model.out_heads[k].load_state_dict(sd, strict=strict)
    if "film" in pkg and getattr(model, "film", None) is not None:
        model.film.load_state_dict(pkg["film"], strict=strict)
    # film_mask : copier seulement si shape compatible
    saved_mask = pkg.get("film_mask", None)
    if isinstance(saved_mask, torch.Tensor) and hasattr(model, "film_mask") and model.film_mask is not None:
        if saved_mask.numel() == model.film_mask.numel():
            with torch.no_grad():
                model.film_mask.copy_(saved_mask.to(model.film_mask.device, dtype=model.film_mask.dtype))
        else:
            print(f"[load_block_A_only] film_mask ignoré (shape incompatibles: saved {tuple(saved_mask.shape)} vs "
                  f"model {tuple(model.film_mask.shape)})")
    return model

def save_block_A_only(model: "PhysicallyInformedAE", path: str):
    ensure_dir(os.path.dirname(path))
    torch.save(extract_state_dict_A_only(model), path)

def extract_state_dict_refiner_only(model: "PhysicallyInformedAE") -> dict:
    return {
        "refiner": model.refiner.state_dict(),
        "_meta": {
            "m_params": int(model.refiner.m_params),
            "cond_dim": int(model.refiner.cond_dim),
            "backbone_feat_dim": int(model.refiner.backbone_feat_dim),
            "delta_scale": float(model.refiner.delta_scale),
        }
    }

def load_block_refiner_only(model: "PhysicallyInformedAE", path: str, strict: bool = False):
    pkg = torch.load(path, map_location="cpu")
    model.refiner.load_state_dict(pkg["refiner"], strict=strict)
    # on peut aussi remettre le delta_scale du paquet (pratique si différent)
    if "_meta" in pkg and "delta_scale" in pkg["_meta"]:
        model.refiner.delta_scale = float(pkg["_meta"]["delta_scale"])
    return model

def save_block_refiner_only(model: "PhysicallyInformedAE", path: str):
    ensure_dir(os.path.dirname(path))
    torch.save(extract_state_dict_refiner_only(model), path)

@torch.no_grad()
def cascade_infer(model: "PhysicallyInformedAE",
                  spectra: torch.Tensor,
                  provided_phys: dict,
                  refiner_weight_paths: List[str]) -> dict:
    """
    Applique A puis une séquence de raffineurs (B1,B2,...) donnés par leurs poids.
    Chaque raffineur met à jour params_pred_norm avant le suivant.
    """
    model.eval()
    device = spectra.device
    B = spectra.shape[0]

    # condition FiLM
    if len(model.film_params) > 0:
        cols = [norm_param_torch(n, provided_phys[n].to(device)).unsqueeze(1) for n in model.film_params]
        cond_norm = torch.cat(cols, dim=1).to(torch.float32)
    else:
        cond_norm = None

    # passe A
    latent, _ = model.backbone(spectra.unsqueeze(1))
    feat_shared = model.feature_head(latent)
    params_pred_norm = model._predict_params_from_features(feat_shared, cond_norm)

    # phys fournis (non prédits)
    if len(model.provided_params) > 0:
        provided_list = [provided_phys[n].to(device) for n in model.provided_params]
        provided_phys_tensor = torch.stack(provided_list, dim=1)
    else:
        provided_phys_tensor = params_pred_norm.new_zeros((B, 0))

    # cascade des raffineurs
    for wpath in refiner_weight_paths or []:
        load_block_refiner_only(model, wpath, strict=False)
        pred_phys  = model._denorm_params_subset(params_pred_norm, model.predict_params)
        y_full     = model._compose_full_phys(pred_phys, provided_phys_tensor)
        recon      = model._physics_reconstruction(y_full, device, None)
        resid      = recon - spectra
        delta      = model.refiner(spectra, resid, params_pred_norm, cond_norm, feat_shared)
        params_pred_norm = params_pred_norm.add(delta).clamp(1e-4, 1-1e-4)

    pred_phys_final = model._denorm_params_subset(params_pred_norm, model.predict_params)
    y_full_final    = model._compose_full_phys(pred_phys_final, provided_phys_tensor)
    recon_final     = model._physics_reconstruction(y_full_final, device, None)
    return {"params_pred_norm": params_pred_norm, "y_phys_full": y_full_final, "spectra_recon": recon_final}

if __name__ == "__main__":
    main()
