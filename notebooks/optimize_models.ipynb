{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimisation des modèles A et B\n",
        "\n",
        "Ce carnet montre comment personnaliser la génération synthétique des données, ajuster le bruit et lancer des recherches Optuna pour les étapes d'entraînement **A** et **B**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chargement du module et configuration\n",
        "\n",
        "Nous exploitons les dataclasses `DataModuleConfig`, `ModelConfig` et `NoiseConfig` pour contrôler la génération des spectres et leurs bruits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import importlib.util, pathlib, sys\n",
        "\n",
        "repo_root = pathlib.Path('..').resolve()\n",
        "spec = importlib.util.spec_from_file_location('physae', repo_root / 'physae')\n",
        "physae = importlib.util.module_from_spec(spec)\n",
        "sys.modules['physae'] = physae\n",
        "spec.loader.exec_module(physae)\n",
        "\n",
        "from physae import (\n",
        "    DataModuleConfig,\n",
        "    ModelConfig,\n",
        "    NoiseConfig,\n",
        "    StageOptimizationConfig,\n",
        "    optimize_stage_with_optuna,\n",
        "    build_data_and_model_from_config,\n",
        "    train_stage_custom,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "data_config = DataModuleConfig(\n",
        "    seed=123,\n",
        "    n_points=256,\n",
        "    n_train=2048,\n",
        "    n_val=512,\n",
        "    batch_size=32,\n",
        "    noise_train=NoiseConfig(\n",
        "        std_add_range=(0.0, 0.005),\n",
        "        std_mult_range=(0.0, 0.01),\n",
        "        p_drift=0.2,\n",
        "        drift_sigma_range=(10.0, 60.0),\n",
        "        drift_amp_range=(0.002, 0.02),\n",
        "        p_fringes=0.2,\n",
        "        fringe_freq_range=(0.5, 6.0),\n",
        "        fringe_amp_range=(0.001, 0.008),\n",
        "    ),\n",
        "    noise_val=NoiseConfig(\n",
        "        std_add_range=(0.0, 0.002),\n",
        "        std_mult_range=(0.0, 0.004),\n",
        "        p_drift=0.0,\n",
        "        p_fringes=0.0,\n",
        "        p_spikes=0.0,\n",
        "    ),\n",
        "    with_noise_train=True,\n",
        "    with_noise_val=True,\n",
        "    freeze_noise_val=True,\n",
        ")\n",
        "\n",
        "model_config = ModelConfig(\n",
        "    lr=1e-4,\n",
        "    base_lr=1e-4,\n",
        "    refiner_lr=5e-5,\n",
        "    predict_params=['sig0', 'dsig', 'mf_CH4', 'P', 'T', 'baseline1', 'baseline2'],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimisation de l'étape A\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "stage_a_config = StageOptimizationConfig(\n",
        "    stage='A',\n",
        "    n_trials=3,\n",
        "    timeout=600,\n",
        "    metric_name='val_loss',\n",
        "    base_stage_kwargs={'epochs': 5, 'enable_progress_bar': False},\n",
        ")\n",
        "\n",
        "study_a, metadata_a = optimize_stage_with_optuna(\n",
        "    stage_a_config,\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        ")\n",
        "print('Meilleur essai (Stage A):', study_a.best_trial.number)\n",
        "print('Hyperparamètres Stage A:', study_a.best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sauvegarde du meilleur modèle A\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "best_stage_a_kwargs = physae._default_stage_kwargs('A')\n",
        "best_stage_a_kwargs.update(stage_a_config.base_stage_kwargs)\n",
        "best_stage_a_kwargs.update(study_a.best_params)\n",
        "best_stage_a_kwargs['ckpt_out'] = 'stage_a_best.ckpt'\n",
        "\n",
        "model_a, train_loader_a, val_loader_a, _ = build_data_and_model_from_config(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        ")\n",
        "train_stage_custom(model_a, train_loader_a, val_loader_a, **best_stage_a_kwargs)\n",
        "stage_a_state = {k: v.cpu() for k, v in model_a.state_dict().items()}\n",
        "print('Métriques Stage A:', getattr(model_a, 'last_stage_metrics', {}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimisation de l'étape B (B2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "stage_b_config = StageOptimizationConfig(\n",
        "    stage='B2',\n",
        "    n_trials=3,\n",
        "    timeout=600,\n",
        "    metric_name='val_loss',\n",
        "    base_stage_kwargs={'epochs': 5, 'enable_progress_bar': False},\n",
        "    initial_state_dict=stage_a_state,\n",
        ")\n",
        "\n",
        "study_b, metadata_b = optimize_stage_with_optuna(\n",
        "    stage_b_config,\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        ")\n",
        "print('Meilleur essai (Stage B):', study_b.best_trial.number)\n",
        "print('Hyperparamètres Stage B:', study_b.best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ré-entraînement final avec les meilleurs réglages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "best_stage_b_kwargs = physae._default_stage_kwargs('B2')\n",
        "best_stage_b_kwargs.update(stage_b_config.base_stage_kwargs)\n",
        "best_stage_b_kwargs.update(study_b.best_params)\n",
        "\n",
        "model_b, train_loader_b, val_loader_b, _ = build_data_and_model_from_config(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        ")\n",
        "model_b.load_state_dict(stage_a_state, strict=False)\n",
        "train_stage_custom(model_b, train_loader_b, val_loader_b, **best_stage_b_kwargs)\n",
        "print('Métriques Stage B:', getattr(model_b, 'last_stage_metrics', {}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Nous avons défini des plages de génération personnalisées, optimisé les hyperparamètres des étapes A et B avec Optuna et ré-entraîné les modèles sur les meilleurs réglages.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}