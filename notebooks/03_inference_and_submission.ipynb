{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "            # PhysAE – inférence et génération de soumissions\n",
        "\n",
        "            Ce carnet démontre comment charger un checkpoint, produire des\n",
        "            prédictions et créer des fichiers de soumission aux formats CSV et\n",
        "            JSON.\n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "            ## 1. Chargement du modèle et des données de test\n",
        "\n",
        "            Nous supposons que `stage_B2.ckpt` est disponible (généré via le carnet\n",
        "            de démarrage rapide ou fourni par l'équipe).\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            from pathlib import Path\n",
        "            import json\n",
        "            import pandas as pd\n",
        "            import torch\n",
        "\n",
        "            from physae.factory import build_data_and_model\n",
        "\n",
        "            ARTIFACT_DIR = Path('artifacts/quickstart')\n",
        "            CKPT_PATH = ARTIFACT_DIR / 'stage_B2.ckpt'\n",
        "            assert CKPT_PATH.exists(), 'Veuillez exécuter le carnet 01 pour générer un checkpoint.'\n",
        "\n",
        "            model = torch.load(CKPT_PATH, map_location='cpu') if CKPT_PATH.suffix == '.pt' else None\n",
        "            if model is None:\n",
        "                from physae.model import PhysicallyInformedAE\n",
        "                model = PhysicallyInformedAE.load_from_checkpoint(str(CKPT_PATH))\n",
        "            model.eval()\n",
        "            if torch.cuda.is_available():\n",
        "                model.cuda()\n",
        "\n",
        "            _, test_loader, _ = build_data_and_model(config_overrides={'n_train': 0, 'n_val': 0, 'batch_size': 16})\n",
        "            print('Nombre de lots de test :', len(test_loader))\n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "            ## 2. Boucle d'inférence\n",
        "\n",
        "            On applique la méthode `infer` du modèle pour chaque lot et on\n",
        "            dénormalise les paramètres physiques avant de les stocker.\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            from physae.normalization import unnorm_param_torch\n",
        "\n",
        "            predictions = []\n",
        "            with torch.no_grad():\n",
        "                for batch in test_loader:\n",
        "                    noisy = batch['noisy_spectra'].to(model.device)\n",
        "                    provided = {\n",
        "                        name: batch['params'][:, model.name_to_idx[name]].to(model.device)\n",
        "                        for name in model.provided_params\n",
        "                    }\n",
        "                    outputs = model.infer(noisy, provided, refine=True)\n",
        "                    phys = outputs['y_phys_full'].cpu()\n",
        "                    for i, sample_id in enumerate(batch['id']):\n",
        "                        row = {'sample_id': sample_id}\n",
        "                        for name in model.predict_params:\n",
        "                            idx = model.name_to_idx[name]\n",
        "                            row[name] = float(unnorm_param_torch(name, phys[i, idx]))\n",
        "                        predictions.append(row)\n",
        "            print('Prédictions collectées :', len(predictions))\n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "            ## 3. Création des fichiers de soumission\n",
        "\n",
        "            Nous générons deux formats : CSV complet et JSON partiel.\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            csv_path = Path('docs/examples/submissions/submission_nominal.csv')\n",
        "            pd.DataFrame(predictions).to_csv(csv_path, index=False)\n",
        "            print('CSV écrit dans', csv_path)\n",
        "\n",
        "            json_path = Path('docs/examples/submissions/submission_partial.json')\n",
        "            json_payload = [\n",
        "                {\n",
        "                    'sample_id': row['sample_id'],\n",
        "                    'params': {k: row[k] for k in model.predict_params[:3]},\n",
        "                    'metadata': {'model': 'PhysAE', 'refine_steps': model.refine_steps},\n",
        "                }\n",
        "                for row in predictions\n",
        "            ]\n",
        "            json_path.write_text(json.dumps(json_payload, indent=2))\n",
        "            print('JSON écrit dans', json_path)\n",
        "            \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}