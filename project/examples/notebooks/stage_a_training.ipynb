{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage A Training: Backbone Encoder\n\n",
        "This notebook walks through Stage\u00a0A of the Physically Informed Autoencoder (PhysAE) training pipeline.\n",
        "Stage\u00a0A optimises the EfficientNet backbone and parameter prediction heads while the cascade refiners remain frozen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n\n",
        "* Python\u00a03.10 or newer\n",
        "* PyTorch, PyTorch Lightning, and the optional Lion optimizer (`pip install torch pytorch-lightning lion-pytorch`)\n",
        "* (Optional) HITRAN TIPS_2021 partition files placed in a `QTpy/` directory at the repository root\n\n",
        "Execute the first code cell below to install runtime dependencies when using a fresh environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# !pip install -q torch pytorch-lightning lion-pytorch numpy pandas matplotlib scipy\n",
        "# Uncomment the line above when running inside a clean environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from types import SimpleNamespace\n",
        "import sys\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# Resolve repository root so we can import the project package\n",
        "REPO_ROOT = Path.cwd().resolve()\n",
        "while not (REPO_ROOT / 'project').exists():\n",
        "    if REPO_ROOT.parent == REPO_ROOT:\n",
        "        raise RuntimeError('Run this notebook from inside the physae repository.')\n",
        "    REPO_ROOT = REPO_ROOT.parent\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "from config.data_config import load_noise_profile, load_parameter_ranges, load_transitions\n",
        "from config.params import PARAMS, NORM_PARAMS\n",
        "from data.dataset import SpectraDataset\n",
        "from models.autoencoder import PhysicallyInformedAE\n",
        "from physics.tips import Tips2021QTpy, find_qtpy_dir\n",
        "from training.callbacks.epoch_sync import UpdateEpochInDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "stage_a = SimpleNamespace(\n",
        "    seed=42,\n",
        "    train_samples=4096,\n",
        "    val_samples=512,\n",
        "    num_points=1024,\n",
        "    batch_size=64,\n",
        "    num_workers=4,\n",
        "    epochs=60,\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-2,\n",
        "    mlp_dropout=0.10,\n",
        "    refiner_dropout=0.05,\n",
        "    backbone_variant='s',\n",
        "    refiner_variant='s',\n",
        "    refine_steps=1,\n",
        "    refine_delta_scale=0.10,\n",
        "    refine_warmup_epochs=30,\n",
        "    freeze_base_epochs=20,\n",
        "    stage3_lr_shrink=0.33,\n",
        "    gpus=1,\n",
        "    precision='32',\n",
        "    log_every_n_steps=50,\n",
        "    checkpoint_dir=REPO_ROOT / 'checkpoints' / 'stage_a',\n",
        "    log_dir=REPO_ROOT / 'logs' / 'stage_a',\n",
        "    qtpy_dir=REPO_ROOT / 'QTpy',\n",
        ")\n",
        "\n",
        "stage_a.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "stage_a.log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pl.seed_everything(stage_a.seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def make_linear_frequency_grid(num_points: int, start: float = 5995.0, end: float = 6005.0) -> list[float]:\n",
        "    step = (end - start) / num_points\n",
        "    coeffs = [start, step, 0.0]\n",
        "    print(f'Frequency grid: {num_points} points from {start} to {end} cm^-1')\n",
        "    print(f'Polynomial coefficients: {coeffs}')\n",
        "    return coeffs\n",
        "\n",
        "parameters_path = REPO_ROOT / 'project' / 'config' / 'data' / 'parameters_default.yaml'\n",
        "noise_path = REPO_ROOT / 'project' / 'config' / 'data' / 'noise_default.yaml'\n",
        "transitions_path = REPO_ROOT / 'project' / 'config' / 'data' / 'transitions_sample.yaml'\n",
        "\n",
        "parameter_ranges = load_parameter_ranges(parameters_path)\n",
        "noise_profile = load_noise_profile(noise_path)\n",
        "transitions = load_transitions(transitions_path)\n",
        "# For the quick-start example we keep only CH4 lines to match the default PARAMS list\n",
        "transitions = {'CH4': transitions.get('CH4', [])}\n",
        "\n",
        "poly_freq = make_linear_frequency_grid(stage_a.num_points)\n",
        "\n",
        "try:\n",
        "    qtpy_dir = find_qtpy_dir(stage_a.qtpy_dir)\n",
        "    tipspy = Tips2021QTpy(qtpy_dir, device='cpu')\n",
        "    print(f'TIPS data loaded from: {qtpy_dir}')\n",
        "except FileNotFoundError:\n",
        "    tipspy = None\n",
        "    print('QTpy directory not found; continuing without partition functions.')\n",
        "\n",
        "train_dataset = SpectraDataset(\n",
        "    n_samples=stage_a.train_samples,\n",
        "    num_points=stage_a.num_points,\n",
        "    poly_freq_CH4=poly_freq,\n",
        "    transitions_dict=transitions,\n",
        "    sample_ranges=NORM_PARAMS,\n",
        "    with_noise=True,\n",
        "    noise_profile=noise_profile,\n",
        "    freeze_noise=False,\n",
        "    tipspy=tipspy,\n",
        ")\n",
        "val_dataset = SpectraDataset(\n",
        "    n_samples=stage_a.val_samples,\n",
        "    num_points=stage_a.num_points,\n",
        "    poly_freq_CH4=poly_freq,\n",
        "    transitions_dict=transitions,\n",
        "    sample_ranges=NORM_PARAMS,\n",
        "    with_noise=True,\n",
        "    noise_profile=noise_profile,\n",
        "    freeze_noise=True,\n",
        "    tipspy=tipspy,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=stage_a.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=stage_a.num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=stage_a.num_workers > 0,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=stage_a.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=stage_a.num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=stage_a.num_workers > 0,\n",
        ")\n",
        "\n",
        "print(f'Training batches: {len(train_loader)}')\n",
        "print(f'Validation batches: {len(val_loader)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "model_kwargs = dict(\n",
        "    n_points=stage_a.num_points,\n",
        "    param_names=PARAMS,\n",
        "    poly_freq_CH4=poly_freq,\n",
        "    transitions_dict=transitions,\n",
        "    tipspy=tipspy,\n",
        "    lr=stage_a.lr,\n",
        "    mlp_dropout=stage_a.mlp_dropout,\n",
        "    refiner_mlp_dropout=stage_a.refiner_dropout,\n",
        "    backbone_variant=stage_a.backbone_variant,\n",
        "    refiner_variant=stage_a.refiner_variant,\n",
        "    refine_steps=stage_a.refine_steps,\n",
        "    refine_delta_scale=stage_a.refine_delta_scale,\n",
        "    refine_warmup_epochs=stage_a.refine_warmup_epochs,\n",
        "    freeze_base_epochs=stage_a.freeze_base_epochs,\n",
        "    stage3_lr_shrink=stage_a.stage3_lr_shrink,\n",
        ")\n",
        "model = PhysicallyInformedAE(**model_kwargs)\n",
        "model.weight_decay = stage_a.weight_decay\n",
        "model.base_lr = stage_a.lr\n",
        "model.refiner_lr = stage_a.lr\n",
        "model.set_stage_mode('A', refine_steps=stage_a.refine_steps, delta_scale=stage_a.refine_delta_scale)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=stage_a.checkpoint_dir,\n",
        "    filename='physae-stage-a-{epoch:03d}-{val_loss:.4f}',\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_last=True,\n",
        "    save_top_k=3,\n",
        ")\n",
        "early_stop_cb = EarlyStopping(monitor='val_loss', mode='min', patience=15, verbose=True)\n",
        "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
        "epoch_sync = UpdateEpochInDataset()\n",
        "\n",
        "accelerator = 'gpu' if stage_a.gpus > 0 and torch.cuda.is_available() else 'cpu'\n",
        "devices = stage_a.gpus if accelerator == 'gpu' else 1\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=stage_a.epochs,\n",
        "    accelerator=accelerator,\n",
        "    devices=devices,\n",
        "    precision=stage_a.precision,\n",
        "    callbacks=[checkpoint_cb, early_stop_cb, lr_monitor, epoch_sync],\n",
        "    log_every_n_steps=stage_a.log_every_n_steps,\n",
        "    gradient_clip_val=1.0,\n",
        "    default_root_dir=stage_a.log_dir,\n",
        "    enable_model_summary=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "trainer.fit(model, train_loader, val_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n\n",
        "* Explore the saved checkpoints under `checkpoints/stage_a/`.\n",
        "* Launch Stage\u00a0B1 training (refiners with the backbone frozen) once validation loss plateaus.\n",
        "* Monitor TensorBoard logs from `logs/stage_a/` to inspect optimisation curves."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}