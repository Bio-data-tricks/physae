{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Stage\u00a0A Training with YAML Configurations\n\nThis notebook shows how to launch the Stage\u00a0A training of **PhysicallyInformedAE** by relying exclusively on the YAML configuration files shipped with the project. The workflow mirrors `physae.py` while keeping everything declarative: parameter ranges, noise settings, and spectroscopic transitions are all loaded from the YAML bundles in `project/config/data/`.\n\n> \u2139\ufe0f **Tip:** You can adapt the same pattern for Stage\u00a0B or the denoiser simply by swapping the training helper that is imported at the end of the notebook."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Locate the repository and configuration files\n\nWhen the notebook is opened from `project/examples/notebooks`, the helper below automatically climbs up to the repository root. Adjust `CONFIG_DIR` if you keep your YAML files somewhere else."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\nimport sys\n\nNOTEBOOK_DIR = Path.cwd().resolve()\nPROJECT_ROOT = NOTEBOOK_DIR\nwhile not (PROJECT_ROOT / 'project' / '__init__.py').exists():\n    if PROJECT_ROOT.parent == PROJECT_ROOT:\n        raise RuntimeError('Could not locate the repository root \u2014 run this notebook from within the physae repo.')\n    PROJECT_ROOT = PROJECT_ROOT.parent\n\nCONFIG_DIR = PROJECT_ROOT / 'project' / 'config' / 'data'\nprint(f'Repository root: {PROJECT_ROOT}')\nprint(f'Configuration directory: {CONFIG_DIR}')\nsys.path.insert(0, str(PROJECT_ROOT / 'project'))\nprint(f\"Python path primed with: {PROJECT_ROOT / 'project'}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Load YAML-driven parameter ranges, noise profile, and transitions\n\nThe helper functions from `config.data_config` parse the YAML files and update the global normalisation tables (`config.params.NORM_PARAMS`, `LOG_SCALE_PARAMS`) so that datasets and models stay consistent."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from config.data_config import load_parameter_ranges, load_noise_profile, load_transitions\nfrom config.params import NORM_PARAMS, LOG_SCALE_PARAMS\n\nparam_ranges = load_parameter_ranges(CONFIG_DIR / 'parameters_default.yaml')\nnoise_profile = load_noise_profile(CONFIG_DIR / 'noise_default.yaml')\ntransitions, poly_freq = load_transitions(CONFIG_DIR / 'transitions_sample.yaml', include_poly_freq=True)\n\n# The sample catalogue includes H2O lines like in physae.py.\n# They require a mole-fraction range; we mirror physae.py's defaults here.\nif 'H2O' in transitions and 'mf_H2O' not in NORM_PARAMS:\n    h2o_range = (1.0e-7, 5.0e-4)\n    NORM_PARAMS['mf_H2O'] = h2o_range\n    param_ranges['mf_H2O'] = h2o_range\n    LOG_SCALE_PARAMS.add('mf_H2O')\n\nprint('Loaded parameter ranges:')\nfor name, (lo, hi) in param_ranges.items():\n    print(f'  - {name}: {lo:.3e} \u2192 {hi:.3e}')\n\nprint('\nTransitions summary:')\nfor mol, entries in transitions.items():\n    print(f'  - {mol}: {len(entries)} lines, poly coeffs = {poly_freq.get(mol)}')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Build synthetic datasets from the YAML configuration\n\n`TrainingConfig` consumes the YAML-driven ranges/noise dictionaries and exposes convenience helpers to create consistent training and validation datasets."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from config.training_config import TrainingConfig\nfrom data.dataset import SpectraDataset\nfrom torch.utils.data import DataLoader\n\nconfig = TrainingConfig(\n    n_points=800,\n    n_train=4096,\n    n_val=512,\n    batch_size=32,\n    train_ranges=param_ranges,\n    val_ranges=param_ranges,\n    noise_train=noise_profile,\n    noise_val=noise_profile,\n    learning_rates=(1e-4, 1e-5),\n)\n\nnoise_train, noise_val = config.resolved_noise_profiles()\ntrain_dataset = SpectraDataset(\n    n_samples=config.n_train,\n    num_points=config.n_points,\n    poly_freq_CH4=poly_freq.get('CH4'),\n    transitions_dict=transitions,\n    sample_ranges=config.resolved_train_ranges(),\n    with_noise=True,\n    noise_profile=noise_train,\n)\nval_dataset = SpectraDataset(\n    n_samples=config.n_val,\n    num_points=config.n_points,\n    poly_freq_CH4=poly_freq.get('CH4'),\n    transitions_dict=transitions,\n    sample_ranges=config.resolved_val_ranges(),\n    with_noise=False,\n    noise_profile=noise_val,\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4)\n\nbatch = next(iter(train_loader))\nprint('Mini-batch keys:', list(batch))\nprint('Noisy spectra shape:', batch['noisy_spectra'].shape)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Instantiate the Lightning module\n\nThe autoencoder shares the same defaults as in `physae.py`. We pass the YAML-derived transitions and optional polynomial frequency coefficients directly into the constructor."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from models.autoencoder import PhysicallyInformedAE\n\nmodel = PhysicallyInformedAE(\n    poly_freq_CH4=poly_freq.get('CH4'),\n    transitions_dict=transitions,\n    **config.model_kwargs(),\n)\n\nprint('Predicting parameters:', model.predict_params)\nprint('Base learning rate:', model.base_lr)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Launch a short Stage\u00a0A run\n\nWe reuse the high-level helper from `training.stages` so the freezing/unfreezing logic matches the original training script. For interactive exploration, a single epoch with a reduced number of batches keeps runtime under a minute on CPU."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from training.stages import train_stage_A\nfrom training.callbacks.loss_curves import LossCurvePlotCallback\n\ncallbacks = [LossCurvePlotCallback()]\n\ntrain_stage_A(\n    model,\n    train_loader,\n    val_loader,\n    epochs=1,\n    enable_progress_bar=True,\n    callbacks=callbacks,\n    limit_train_batches=2,\n    limit_val_batches=2,\n    accelerator='cpu',\n    devices=1,\n)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Next steps\n\n- Increase `epochs`, remove the `limit_*_batches` caps, and point `Trainer` to your GPU(s) for a full training run.\n- Swap `train_stage_A` for `train_stage_B1`, `train_stage_B2`, or `train_refiner_idx` to continue the staged fine-tuning.\n- Provide your own YAML files and re-run the notebook; the same code path will load them without changes."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}