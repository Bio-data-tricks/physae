{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage A Diagnostic Notebook\n",
        "\n",
        "Ce notebook reproduit un entra\u00eenement *Stage A* minimal du mod\u00e8le `PhysicallyInformedAE` afin de v\u00e9rifier que les pertes diminuent correctement et que le mod\u00e8le apprend bien.\n",
        "\n",
        "Les \u00e9tapes cl\u00e9s sont :\n",
        "1. Pr\u00e9paration d'un jeu de donn\u00e9es synth\u00e9tique r\u00e9duit (bruit inclus).\n",
        "2. Instanciation du mod\u00e8le avec la configuration `TrainingConfig`.\n",
        "3. Lancement d'un Stage A de quelques \u00e9poques avec les callbacks d'actualisation d'\u00e9poque.\n",
        "4. V\u00e9rification rapide des pertes sur un mini-lot de validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "pl.seed_everything(42)\n",
        "torch.set_float32_matmul_precision(\"high\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from project.config.training_config import TrainingConfig\n",
        "from project.data.dataset import SpectraDataset\n",
        "from project.data.loaders import create_dataloader\n",
        "from project.models.autoencoder import PhysicallyInformedAE\n",
        "from project.training.callbacks.epoch_sync import (\n",
        "    UpdateEpochInDataset,\n",
        "    UpdateEpochInValDataset,\n",
        ")\n",
        "from project.training.stages import train_stage_A\n",
        "\n",
        "# Configuration compacte pour un diagnostic rapide\n",
        "cfg = TrainingConfig(\n",
        "    n_points=512,\n",
        "    n_train=512,\n",
        "    n_val=128,\n",
        "    batch_size=32,\n",
        "    learning_rates=(3e-4, 1e-4),\n",
        ")\n",
        "\n",
        "# Pas de lignes spectrales explicites pour ce test rapide\n",
        "transitions_dict = {}\n",
        "poly_freq = None\n",
        "\n",
        "train_dataset = SpectraDataset(\n",
        "    n_samples=cfg.n_train,\n",
        "    num_points=cfg.n_points,\n",
        "    poly_freq_CH4=poly_freq,\n",
        "    transitions_dict=transitions_dict,\n",
        "    sample_ranges=cfg.resolved_train_ranges(),\n",
        "    with_noise=True,\n",
        ")\n",
        "train_dataset.freeze_parameter_draws(True)\n",
        "\n",
        "val_dataset = SpectraDataset(\n",
        "    n_samples=cfg.n_val,\n",
        "    num_points=cfg.n_points,\n",
        "    poly_freq_CH4=poly_freq,\n",
        "    transitions_dict=transitions_dict,\n",
        "    sample_ranges=cfg.resolved_val_ranges(),\n",
        "    with_noise=True,\n",
        "    freeze_noise=True,\n",
        ")\n",
        "val_dataset.freeze_parameter_draws(True)\n",
        "\n",
        "train_loader = create_dataloader(\n",
        "    train_dataset,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "val_loader = create_dataloader(\n",
        "    val_dataset,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(\"Noisy spectra shape:\", batch[\"noisy_spectra\"].shape)\n",
        "print(\"Clean spectra shape:\", batch[\"clean_spectra\"].shape)\n",
        "print(\"Params shape:\", batch[\"params\"].shape)\n",
        "print(\"Noisy mean |value|:\", batch[\"noisy_spectra\"].abs().mean().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pr\u00e9paration du mod\u00e8le et des callbacks Stage A\n",
        "model_kwargs = cfg.model_kwargs()\n",
        "model_kwargs.update(cfg.stage_overrides(\"A\"))\n",
        "model = PhysicallyInformedAE(\n",
        "    **model_kwargs,\n",
        "    transitions_dict=transitions_dict,\n",
        "    poly_freq_CH4=poly_freq,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    UpdateEpochInDataset(),\n",
        "    UpdateEpochInValDataset(),\n",
        "]\n",
        "\n",
        "trained_model = train_stage_A(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=5,\n",
        "    base_lr=3e-4,\n",
        "    enable_progress_bar=True,\n",
        "    callbacks=callbacks,\n",
        "    accelerator=\"cpu\",\n",
        "    devices=1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "trained_model.eval()\n",
        "val_batch = next(iter(val_loader))\n",
        "with torch.no_grad():\n",
        "    loss_val = trained_model._common_step(val_batch, \"val\")\n",
        "\n",
        "print(f\"Validation loss (snapshot apr\u00e8s Stage A): {loss_val.item():.6f}\")\n",
        "\n",
        "# Comparaison rapide des param\u00e8tres pr\u00e9dits vs cibles normalis\u00e9es\n",
        "with torch.no_grad():\n",
        "    latent, _ = trained_model.backbone(val_batch[\"noisy_spectra\"].unsqueeze(1))\n",
        "    feats = trained_model._pool_features(latent)\n",
        "    params_pred_norm = trained_model._predict_params_from_features(feats)\n",
        "\n",
        "print(\"Mean predicted param (normed):\", params_pred_norm.mean().item())\n",
        "print(\"Mean target param (normed):\", val_batch[\"params\"].mean().item())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}